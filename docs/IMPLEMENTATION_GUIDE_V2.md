# ðŸš€ GuÃ­a de ImplementaciÃ³n v2.0 - Quantum & GPU Enhancement

**Fecha:** Octubre 2025  
**Estado:** âœ… Fase 1 Iniciada - GPU Embedding Service

---

## âœ… Estado Actual de ImplementaciÃ³n

### Completado

- âœ… Estructura de carpetas creada (`services/`)
- âœ… **GPU Embedding Service** implementado y listo
  - `main.py` - Servicio FastAPI completo
  - `requirements.txt` - Dependencias
  - `Dockerfile` - Contenedor con soporte CUDA
  - `README.md` - DocumentaciÃ³n completa
  - `.env.example` - ConfiguraciÃ³n de ejemplo
- âœ… `docker-compose.quantum-gpu.yml` - OrquestaciÃ³n de nuevos servicios
- âœ… Prometheus + Grafana configurados para monitoreo

### En Progreso

- ðŸš§ Quantum services (pendientes de implementaciÃ³n)
- ðŸš§ RAG Enhanced service (pendiente)
- ðŸš§ ConfiguraciÃ³n de Prometheus
- ðŸš§ Dashboards de Grafana

---

## ðŸŽ¯ CÃ³mo Usar el GPU Embedding Service

### OpciÃ³n 1: Docker Compose (Recomendado)

```bash
# 1. Levantar SOLO el servicio GPU (sin afectar app actual)
docker-compose -f docker-compose.quantum-gpu.yml up gpu-embedding-service -d

# 2. Verificar que estÃ¡ corriendo
curl http://localhost:8001/health

# 3. Ver logs
docker logs financia_gpu_embedding -f

# 4. Probar generaciÃ³n de embeddings
curl -X POST http://localhost:8001/api/v1/embeddings/generate \
  -H "Content-Type: application/json" \
  -d '{"texts": ["Hola mundo", "Hello world"]}'
```

### OpciÃ³n 2: Levantar TODO (GPU + Monitoring)

```bash
# Levantar GPU service + Prometheus + Grafana
docker-compose -f docker-compose.quantum-gpu.yml up -d

# Acceder a servicios:
# - GPU Service: http://localhost:8001
# - GPU Docs: http://localhost:8001/docs
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3001 (admin/admin)
```

### OpciÃ³n 3: Desarrollo Local

```bash
cd services/gpu-embedding

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar
python main.py

# Servicio disponible en http://localhost:8001
```

---

## ðŸ”— IntegraciÃ³n con App Actual

### Estrategia: Feature Flag (Recomendado)

El servicio GPU es **completamente independiente**. Para integrarlo:

#### 1. AÃ±adir Variable de Entorno

En `backend/.env`:
```env
# Feature Flag para GPU Embeddings
USE_GPU_EMBEDDINGS=false  # Cambiar a true para activar
GPU_EMBEDDING_URL=http://localhost:8001
```

#### 2. Modificar Servicio de Embeddings (Opcional)

En `backend/services/embedding_service.py` (o similar):

```python
import os
import httpx

USE_GPU = os.getenv("USE_GPU_EMBEDDINGS", "false").lower() == "true"
GPU_URL = os.getenv("GPU_EMBEDDING_URL", "http://localhost:8001")

async def generate_embeddings(texts: List[str]):
    if USE_GPU:
        # Usar servicio GPU
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{GPU_URL}/api/v1/embeddings/generate",
                json={"texts": texts}
            )
            return response.json()["embeddings"]
    else:
        # Usar mÃ©todo actual (fallback)
        return current_embedding_method(texts)
```

#### 3. Testing

```bash
# Test con GPU desactivado (usa mÃ©todo actual)
USE_GPU_EMBEDDINGS=false python test_embeddings.py

# Test con GPU activado
USE_GPU_EMBEDDINGS=true python test_embeddings.py
```

---

## ðŸ“Š Monitoreo y MÃ©tricas

### Prometheus

Accede a mÃ©tricas en:
- GPU Service: http://localhost:8001/metrics
- Prometheus UI: http://localhost:9090

MÃ©tricas disponibles:
```
embeddings_generated_total
embedding_duration_seconds
gpu_memory_used_bytes
active_requests
```

### Grafana

1. Accede a http://localhost:3001
2. Login: `admin` / `admin`
3. Importar dashboard (prÃ³ximamente)

---

## ðŸ§ª Testing y ValidaciÃ³n

### Test BÃ¡sico

```bash
# Health check
curl http://localhost:8001/health

# Respuesta esperada:
{
  "status": "healthy",
  "gpu_available": true,
  "device": "cuda",
  "model_loaded": true,
  "faiss_index_size": 0
}
```

### Test de Embeddings

```bash
curl -X POST http://localhost:8001/api/v1/embeddings/generate \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["documento de prueba", "test document"],
    "normalize": true
  }'
```

### Test de BÃºsqueda

```bash
# 1. AÃ±adir documentos al Ã­ndice
curl -X POST http://localhost:8001/api/v1/index/add \
  -H "Content-Type: application/json" \
  -d '["documento 1", "documento 2", "documento 3"]'

# 2. Buscar similares
curl -X POST http://localhost:8001/api/v1/similarity/search \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "documento",
    "top_k": 5
  }'
```

---

## ðŸ“ˆ Benchmarks Esperados

### Con GPU (NVIDIA RTX 4070)

| OperaciÃ³n | Tiempo | Throughput |
|-----------|--------|------------|
| 1 embedding | <10ms | ~100 docs/s |
| Batch 10 | ~15ms | ~666 docs/s |
| Batch 100 | ~100ms | ~1000 docs/s |
| Batch 1000 | ~1s | ~1000 docs/s |

### Sin GPU (CPU Fallback)

| OperaciÃ³n | Tiempo | Throughput |
|-----------|--------|------------|
| 1 embedding | ~200ms | ~5 docs/s |
| Batch 10 | ~500ms | ~20 docs/s |
| Batch 100 | ~2s | ~50 docs/s |

**Mejora esperada: 10-20x mÃ¡s rÃ¡pido con GPU**

---

## ðŸ”§ Troubleshooting

### GPU No Detectada

```bash
# Verificar NVIDIA driver
nvidia-smi

# Verificar Docker con GPU
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# Verificar NVIDIA Container Toolkit
docker run --rm --gpus all ubuntu nvidia-smi
```

### Servicio No Inicia

```bash
# Ver logs
docker logs financia_gpu_embedding

# Verificar puerto
netstat -an | findstr 8001

# Reiniciar servicio
docker-compose -f docker-compose.quantum-gpu.yml restart gpu-embedding-service
```

### Out of Memory

```bash
# Reducir batch size en requests
# Usar modelo mÃ¡s pequeÃ±o
# Editar .env:
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Reiniciar
docker-compose -f docker-compose.quantum-gpu.yml restart gpu-embedding-service
```

---

## ðŸš€ PrÃ³ximos Pasos

### Semana 1-2: ValidaciÃ³n GPU Service

- [ ] Levantar servicio GPU
- [ ] Ejecutar benchmarks
- [ ] Comparar con mÃ©todo actual
- [ ] Documentar resultados
- [ ] Decidir si integrar en app principal

### Semana 3-4: Quantum Services (Fase 2)

- [ ] Implementar `quantum-dwave-service`
- [ ] Implementar `quantum-ibm-service`
- [ ] Testing de deduplicaciÃ³n
- [ ] Benchmarks vs mÃ©todo clÃ¡sico

### Semana 5-6: RAG Enhanced (Fase 5)

- [ ] Implementar `rag-enhanced-service`
- [ ] Integrar con GPU embeddings
- [ ] Testing de calidad de respuestas
- [ ] Comparar con RAG actual

---

## ðŸ“ Notas Importantes

### âœ… GarantÃ­as

- **NO rompe nada**: Servicios completamente independientes
- **Opcional**: Se puede activar/desactivar con feature flags
- **Fallback**: Si falla, usa mÃ©todo actual automÃ¡ticamente
- **Monitoreado**: MÃ©tricas completas en Prometheus

### âš ï¸ Requisitos

- **GPU**: NVIDIA con CUDA 12.1+ (opcional, funciona en CPU)
- **RAM**: 8GB mÃ­nimo (16GB recomendado)
- **Disco**: 10GB para modelos
- **Docker**: 24.0+ con NVIDIA Container Toolkit

### ðŸ” Seguridad

- Todos los servicios en red privada Docker
- Sin exposiciÃ³n externa por defecto
- API keys en variables de entorno
- Logs sin informaciÃ³n sensible

---

## ðŸ“š DocumentaciÃ³n Adicional

- [Plan Completo](QUANTUM_GPU_ENHANCEMENT_PLAN.md)
- [GPU Service README](../services/gpu-embedding/README.md)
- [Docker Compose](../docker-compose.quantum-gpu.yml)

---

## ðŸ¤ Soporte

**Equipo:** FinancIA 2030 Team  
**Email:** financia2030@tefinancia.es  
**Docs:** [docs/](.)

---

**Â© 2025 TeFinancia S.A. - Confidencial**
