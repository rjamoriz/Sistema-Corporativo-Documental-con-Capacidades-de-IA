# ‚úÖ Integraci√≥n de OpenAI API Completada

**Fecha:** 9 de octubre de 2025  
**Estado:** ‚úÖ CONFIGURADO Y TESTEADO EXITOSAMENTE

---

## üéØ Lo que se ha configurado:

### 1. **OpenAI API Token Integrado**
- ‚úÖ Token agregado al archivo `backend/.env`
- ‚úÖ Token verificado y funcionando
- ‚úÖ Modelo configurado: `gpt-4o-mini`
- ‚úÖ Test exitoso: primera llamada completada (31 tokens)

### 2. **Variables de Entorno Configuradas**

Archivo: `backend/.env`

```env
# OpenAI API - CONFIGURADO
OPENAI_API_KEY=sk-proj-YOUR-ACTUAL-API-KEY-HERE
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=2000

# LLM Provider
LLM_PROVIDER=openai

# Arize Phoenix - Observabilidad
PHOENIX_ENABLE_SERVER=true
PHOENIX_ENABLE_INSTRUMENTATION=true
PHOENIX_HOST=http://localhost
PHOENIX_PORT=6006
PHOENIX_PROJECT_NAME=financia-2030-rag
```

### 3. **Seguridad Configurada**
- ‚úÖ Archivo `.gitignore` creado (el `.env` NO se subir√° a GitHub)
- ‚úÖ Token protegido localmente
- ‚ö†Ô∏è **IMPORTANTE:** Nunca compartas este token p√∫blicamente

### 4. **Test de Conexi√≥n**
- ‚úÖ Script de test creado: `backend/test_openai_phoenix.py`
- ‚úÖ Conexi√≥n con OpenAI verificada
- ‚úÖ Respuesta recibida: "Test exitoso."
- ‚úÖ Tokens consumidos: 31 tokens

---

## üöÄ C√≥mo usar el sistema ahora:

### Opci√≥n 1: Usar solo OpenAI (sin infraestructura completa)

```bash
# 1. Ir al directorio backend
cd backend

# 2. Instalar dependencias b√°sicas (si no lo has hecho)
pip install python-dotenv openai fastapi uvicorn

# 3. Crear un script de prueba simple
python << 'EOF'
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "Eres un asistente financiero experto."},
        {"role": "user", "content": "¬øQu√© es un RAG en sistemas de IA?"}
    ]
)

print(response.choices[0].message.content)
EOF
```

### Opci√≥n 2: Iniciar sistema completo con Phoenix

```bash
# 1. Iniciar infraestructura Docker (incluye Phoenix)
cd infrastructure/docker
docker-compose up -d

# 2. Esperar a que los servicios est√©n listos
docker-compose ps

# 3. Iniciar backend
cd ../../backend
source venv/bin/activate  # Si usas venv
pip install -r requirements.txt
uvicorn main:app --reload

# 4. Acceder a las interfaces
# Backend API: http://localhost:8000/docs
# Phoenix UI: http://localhost:6006
# Frontend: http://localhost:3000 (si lo inicias)
```

### Opci√≥n 3: Solo probar RAG sin infraestructura

Crea un archivo `test_rag_simple.py`:

```python
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Simular un contexto RAG
context = """
[DOC-1] El contrato tiene un plazo de 24 meses renovables.
[DOC-2] La cl√°usula 5.1 establece una penalizaci√≥n del 10% por cancelaci√≥n anticipada.
[DOC-3] El monto total del contrato es de ‚Ç¨50,000.
"""

query = "¬øCu√°l es el plazo del contrato y cu√°nto cuesta?"

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role": "system",
            "content": "Eres un asistente que responde SOLO bas√°ndote en el contexto proporcionado. Siempre cita las fuentes con [DOC-X]."
        },
        {
            "role": "user",
            "content": f"Contexto:\n{context}\n\nPregunta: {query}"
        }
    ],
    temperature=0.1,
    max_tokens=200
)

print("=" * 60)
print("RESPUESTA RAG:")
print("=" * 60)
print(response.choices[0].message.content)
print("=" * 60)
print(f"Tokens usados: {response.usage.total_tokens}")
print(f"Costo aprox: ${response.usage.total_tokens * 0.00000015:.6f}")
```

Ejecutar:
```bash
cd backend
python test_rag_simple.py
```

---

## üìä Costos de OpenAI

Con el modelo **gpt-4o-mini**:

| Concepto | Precio | Ejemplo |
|----------|--------|---------|
| Input tokens | $0.150 / 1M tokens | 1,000 tokens = $0.00015 |
| Output tokens | $0.600 / 1M tokens | 1,000 tokens = $0.00060 |
| Query t√≠pica RAG | ~500 tokens | ~$0.0003 por query |
| 1,000 queries | ~500k tokens | ~$0.30 |
| 10,000 queries | ~5M tokens | ~$3.00 |

**Estimaci√≥n para tu caso de uso (100k docs/a√±o):**
- ~10,000 queries/mes
- Costo mensual: ~$3-5 USD
- Costo anual: ~$36-60 USD

---

## üîç Verificar el funcionamiento

### 1. Test r√°pido de OpenAI
```bash
cd backend
python test_openai_phoenix.py
```

Deber√≠as ver:
```
‚úÖ Conexi√≥n exitosa!
üìù Respuesta: Test exitoso.
üí∞ Tokens usados: 31
```

### 2. Ver el token configurado (enmascarado)
```bash
cd backend
grep OPENAI_API_KEY .env | head -c 50
```

### 3. Verificar que `.env` NO est√° en git
```bash
git status
# No deber√≠a aparecer backend/.env
```

---

## üìö Pr√≥ximos pasos recomendados:

### 1. **Probar RAG completo**
```bash
# Iniciar solo los servicios necesarios para RAG
cd infrastructure/docker
docker-compose up -d postgres opensearch redis phoenix

# Iniciar backend
cd ../../backend
uvicorn main:app --reload
```

### 2. **Acceder a Phoenix Dashboard**
- URL: http://localhost:6006
- Aqu√≠ ver√°s todas las llamadas LLM en tiempo real

### 3. **Hacer una query de prueba**
```bash
curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "¬øCu√°l es el plazo del contrato?",
    "category": "LEGAL"
  }'
```

### 4. **Ver la traza en Phoenix**
- Ir a http://localhost:6006
- Ver la traza completa con:
  - Prompt enviado
  - Respuesta recibida
  - Tokens usados
  - Latencia
  - Contexto recuperado

---

## üêõ Troubleshooting

### Problema: "OpenAI API key not found"
**Soluci√≥n:**
```bash
# Verificar que el archivo existe
ls -la backend/.env

# Verificar que tiene el token
grep OPENAI_API_KEY backend/.env
```

### Problema: "Rate limit exceeded"
**Soluci√≥n:**
- Espera 60 segundos (l√≠mite de OpenAI)
- O reduce la frecuencia de llamadas
- O aumenta los l√≠mites en tu cuenta OpenAI

### Problema: Phoenix no se inicia
**Soluci√≥n:**
```bash
# Ver logs de Phoenix
cd infrastructure/docker
docker-compose logs -f phoenix

# Reiniciar Phoenix
docker-compose restart phoenix
```

### Problema: "Invalid API key"
**Soluci√≥n:**
1. Verifica el token en: https://platform.openai.com/api-keys
2. Aseg√∫rate de que est√° activo y no ha expirado
3. Genera un nuevo token si es necesario
4. Actualiza `backend/.env` con el nuevo token

---

## ‚úÖ Checklist de verificaci√≥n

- [x] ‚úÖ OpenAI API token configurado en `.env`
- [x] ‚úÖ Token verificado y funcionando
- [x] ‚úÖ `.gitignore` configurado (token protegido)
- [x] ‚úÖ Phoenix configurado para observabilidad
- [x] ‚úÖ Test de conexi√≥n exitoso
- [x] ‚úÖ Modelo `gpt-4o-mini` funcionando
- [ ] ‚è≥ Infraestructura Docker iniciada (pendiente)
- [ ] ‚è≥ Primera query RAG completa (pendiente)
- [ ] ‚è≥ Verificar trazas en Phoenix UI (pendiente)

---

## üìñ Documentaci√≥n relacionada

- üìò **OpenAI API:** https://platform.openai.com/docs
- üîç **Phoenix Observability:** `docs/PHOENIX_OBSERVABILITY.md`
- üöÄ **Quick Start:** `QUICKSTART.md`
- üìä **Arquitectura:** `docs/ARCHITECTURE.md`

---

**üéâ ¬°Todo listo! Tu sistema ya tiene OpenAI integrado y funcionando.**

**Pr√≥ximo paso:** Iniciar la infraestructura con `docker-compose up -d` y hacer tu primera query RAG.
