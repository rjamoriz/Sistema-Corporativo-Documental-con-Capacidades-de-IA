# ğŸ” Arize Phoenix - Observabilidad de LLMs

## ğŸ“Š DescripciÃ³n

**Arize Phoenix** es una plataforma de observabilidad de cÃ³digo abierto diseÃ±ada especÃ­ficamente para aplicaciones de LLM (Large Language Models). Permite monitorear, debuggear y mejorar sistemas RAG y agentes de IA con tracking completo de:

- âœ… **Prompts y respuestas** - Trazabilidad completa de interacciones
- âœ… **MÃ©tricas de rendimiento** - Latencia, tokens, costos
- âœ… **Calidad de respuestas** - DetecciÃ³n de alucinaciones, toxicidad
- âœ… **Retrieval effectiveness** - Relevancia de documentos recuperados
- âœ… **ComparaciÃ³n de modelos** - A/B testing de diferentes LLMs

---

## ğŸš€ Inicio RÃ¡pido

### 1. Iniciar Phoenix con Docker

```bash
# Iniciar con docker-compose (incluye Phoenix)
cd infrastructure/docker
docker-compose up -d phoenix

# O ejecutar Phoenix standalone
docker run -p 6006:6006 -p 4317:4317 -p 4318:4318 arizephoenix/phoenix:latest
```

### 2. Acceder a Phoenix UI

Abre tu navegador en: **http://localhost:6006**

VerÃ¡s el dashboard principal con:
- ğŸ“Š **Traces** - Registro de todas las llamadas LLM
- ğŸ“ˆ **Evaluations** - MÃ©tricas de calidad
- ğŸ” **Search** - Buscar por queries especÃ­ficas
- ğŸ“ **Projects** - Diferentes experimentos

### 3. Configurar Variables de Entorno

Crea o actualiza tu archivo `.env` en `/backend`:

```env
# OpenAI API Key (REQUERIDO)
OPENAI_API_KEY=sk-proj-your-api-key-here

# Phoenix Configuration
PHOENIX_ENABLE_SERVER=true
PHOENIX_ENABLE_INSTRUMENTATION=true
PHOENIX_HOST=http://localhost
PHOENIX_PORT=6006
PHOENIX_PROJECT_NAME=financia-2030-rag

# LLM Provider
LLM_PROVIDER=openai  # openai, anthropic, local
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000
```

### 4. Iniciar Backend con Phoenix

```bash
cd backend
source venv/bin/activate

# Instalar dependencias de Phoenix si no estÃ¡n
pip install arize-phoenix openinference-instrumentation-openai

# Iniciar aplicaciÃ³n
uvicorn main:app --reload
```

DeberÃ­as ver en los logs:
```
âœ… Phoenix observability initialized
ğŸ“Š Phoenix UI: http://localhost:6006
```

---

## ğŸ“– Uso en el CÃ³digo

### InstrumentaciÃ³n AutomÃ¡tica (OpenAI)

Phoenix instrumenta automÃ¡ticamente todas las llamadas a OpenAI:

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

# Esta llamada serÃ¡ automÃ¡ticamente trackeada por Phoenix
response = await client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "Eres un asistente Ãºtil"},
        {"role": "user", "content": "Â¿QuÃ© es RAG?"}
    ]
)
```

### Logging Manual de RAG Query

En `rag_service.py`, cada query completa se registra:

```python
from backend.core.phoenix_config import get_phoenix

phoenix = get_phoenix()
phoenix.log_rag_query(
    query="Â¿CuÃ¡l es el plazo del contrato?",
    response="El contrato tiene un plazo de 24 meses [DOC-1]",
    chunks_used=[{
        "document_id": "abc123",
        "filename": "contrato.pdf",
        "score": 0.89
    }],
    model="gpt-4o-mini",
    tokens_used=245,
    latency_ms=1234.5
)
```

### Logging Personalizado

```python
from backend.core.phoenix_config import log_llm_call

log_llm_call(
    prompt="Analiza este documento...",
    response="El documento contiene...",
    model="gpt-4o-mini",
    user_id="user-123",
    document_id="doc-456",
    category="LEGAL"
)
```

---

## ğŸ“Š MÃ©tricas Disponibles en Phoenix

### 1. **Traces (Trazas)**

Cada llamada LLM genera una traza con:
- ğŸ• **Timestamp** - CuÃ¡ndo se realizÃ³
- â±ï¸ **Latencia** - Tiempo de respuesta en ms
- ğŸ¯ **Input** - Prompt completo
- ğŸ“ **Output** - Respuesta del LLM
- ğŸ’° **Tokens** - Prompt + completion tokens
- ğŸ·ï¸ **Model** - gpt-4o-mini, claude-3, etc.
- ğŸ“ **Metadata** - user_id, document_id, etc.

### 2. **Evaluations (Evaluaciones)**

Phoenix puede evaluar automÃ¡ticamente:
- **Hallucination** - Â¿La respuesta estÃ¡ fundamentada?
- **Toxicity** - Â¿Contenido inapropiado?
- **Relevance** - Â¿Responde a la pregunta?
- **Coherence** - Â¿Es coherente la respuesta?

### 3. **Embeddings**

Visualiza embeddings en 2D/3D para:
- Ver clusters de queries similares
- Identificar outliers
- Analizar cobertura de documentos

### 4. **Retrieval Analysis**

Para sistemas RAG:
- **Precision@K** - PrecisiÃ³n de retrieval
- **Recall@K** - Cobertura de retrieval
- **NDCG** - Normalized Discounted Cumulative Gain
- **Hit Rate** - % de queries con al menos 1 documento relevante

---

## ğŸ” Casos de Uso

### 1. Debugging de Alucinaciones

**Problema:** El LLM responde con informaciÃ³n incorrecta.

**SoluciÃ³n con Phoenix:**
1. Buscar la query en Phoenix UI
2. Ver el trace completo con contexto recuperado
3. Comparar respuesta con chunks recuperados
4. Identificar si el problema es:
   - âŒ Retrieval (chunks incorrectos)
   - âŒ LLM (ignora contexto)
   - âŒ Prompt (instrucciones ambiguas)

**Ejemplo:**
```
Query: "Â¿CuÃ¡nto cuesta el producto X?"
Context: [DOC-1] El producto Y cuesta $100
Response: "El producto X cuesta $100" âŒ ALUCINACIÃ“N

Fix: Mejorar retrieval o prompt con verificaciÃ³n mÃ¡s estricta
```

### 2. OptimizaciÃ³n de Costos

**AnÃ¡lisis en Phoenix:**
- Ver distribuciÃ³n de tokens por query
- Identificar queries que usan demasiados tokens
- Detectar contexto redundante

**Ejemplo:**
```
Antes: Promedio 1500 tokens/query = $0.003/query
DespuÃ©s: Optimizar contexto a 800 tokens = $0.0016/query
Ahorro: 47% en costos LLM
```

### 3. A/B Testing de Modelos

**Comparar:**
- gpt-4o-mini vs gpt-4o
- gpt-4 vs claude-3-sonnet
- Diferentes temperaturas (0.1 vs 0.7)

**MÃ©tricas:**
- Latencia promedio
- Calidad de respuestas (hallucination rate)
- Costo por query
- User satisfaction (si se recolecta feedback)

### 4. Mejora Continua de Prompts

**Workflow:**
1. Ejecutar 100 queries de prueba
2. Analizar en Phoenix quÃ© prompts fallan
3. Iterar sobre prompt template
4. Re-ejecutar y comparar mÃ©tricas

---

## ğŸ“ˆ Dashboard de Phoenix

### Vista Principal (Traces)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phoenix - financia-2030-rag                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ“Š MÃ©tricas Generales (Ãºltimas 24h)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Total Traces â”‚ Avg Latency  â”‚ Total Tokens â”‚       â”‚
â”‚  â”‚     1,234    â”‚    1.2s      â”‚   245,678    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  ğŸ“ Traces Recientes                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Time   â”‚ Query    â”‚ Latency â”‚ Status       â”‚       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  â”‚ 10:30  â”‚ Â¿CuÃ¡l... â”‚ 1.2s    â”‚ âœ… Success  â”‚       â”‚
â”‚  â”‚ 10:29  â”‚ Resumen..â”‚ 2.1s    â”‚ âœ… Success  â”‚       â”‚
â”‚  â”‚ 10:28  â”‚ Â¿QuÃ©...  â”‚ 0.8s    â”‚ âš ï¸ Warning  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  [Ver Detalles] [Evaluaciones] [Exportar]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vista de Trace Individual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace: abc123-def456                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ• Timestamp: 2025-10-09 10:30:45                      â”‚
â”‚  â±ï¸ Latency: 1,234 ms                                   â”‚
â”‚  ğŸ¯ Model: gpt-4o-mini                                   â”‚
â”‚  ğŸ’° Tokens: 245 (150 prompt + 95 completion)           â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¥ INPUT (Prompt)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ System: Eres un asistente experto...           â”‚  â”‚
â”‚  â”‚                                                 â”‚  â”‚
â”‚  â”‚ Context:                                        â”‚  â”‚
â”‚  â”‚ [DOC-1] El contrato establece un plazo de...   â”‚  â”‚
â”‚  â”‚ [DOC-2] La clÃ¡usula 5.1 indica...              â”‚  â”‚
â”‚  â”‚                                                 â”‚  â”‚
â”‚  â”‚ User: Â¿CuÃ¡l es el plazo del contrato?          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¤ OUTPUT (Response)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ El contrato tiene un plazo de 24 meses [DOC-1] â”‚  â”‚
â”‚  â”‚ segÃºn se establece en la clÃ¡usula...            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                         â”‚
â”‚  ğŸ” Retrieval Context                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Doc ID  â”‚ Filename         â”‚ Score  â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ DOC-1   â”‚ contrato.pdf     â”‚ 0.89   â”‚              â”‚
â”‚  â”‚ DOC-2   â”‚ anexo_legal.pdf  â”‚ 0.76   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                         â”‚
â”‚  âœ… Evaluations                                         â”‚
â”‚  Hallucination: LOW (0.12)                              â”‚
â”‚  Relevance: HIGH (0.91)                                 â”‚
â”‚  Coherence: HIGH (0.88)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Evaluadores Personalizados

Puedes configurar evaluadores custom en Phoenix:

```python
import phoenix as px
from phoenix.evals import (
    HallucinationEvaluator,
    RelevanceEvaluator,
    ToxicityEvaluator
)

# Configurar evaluadores
hallucination_eval = HallucinationEvaluator()
relevance_eval = RelevanceEvaluator()

# Aplicar a traces
evaluations = px.evaluate(
    dataframe=traces_df,
    evaluators=[hallucination_eval, relevance_eval]
)
```

### Exportar Datos

```python
import phoenix as px

# Obtener todas las traces
traces = px.get_traces(project_name="financia-2030-rag")

# Exportar a Pandas DataFrame
df = traces.to_dataframe()

# Exportar a CSV
df.to_csv("phoenix_traces_export.csv")

# AnÃ¡lisis personalizado
high_latency = df[df['latency_ms'] > 2000]
print(f"Queries lentas: {len(high_latency)}")
```

---

## ğŸ¯ Best Practices

### 1. **Naming Convention**

Usa nombres descriptivos para spans:

```python
with tracer.start_as_current_span("rag_query_legal_contract") as span:
    span.set_attribute("category", "LEGAL")
    span.set_attribute("user_department", "legal")
```

### 2. **Metadata Rica**

Incluye contexto relevante:

```python
phoenix.log_rag_query(
    query=query,
    response=response,
    chunks_used=chunks,
    model=model,
    tokens_used=tokens,
    latency_ms=latency,
    # Metadata adicional
    user_id=user_id,
    document_category=category,
    risk_level=risk_level,
    compliance_status=compliance
)
```

### 3. **Sampling para ProducciÃ³n**

En PROD, considera sampling para reducir volumen:

```python
# Ejemplo: 10% sampling
import random

if random.random() < 0.1:
    phoenix.log_rag_query(...)
```

### 4. **Alerts y Monitoring**

Configura alertas para:
- â— Latencia > 5s
- â— Hallucination rate > 10%
- â— Error rate > 5%
- â— Cost por dÃ­a > umbral

---

## ğŸ“š Recursos Adicionales

- ğŸ“– **DocumentaciÃ³n oficial:** https://docs.arize.com/phoenix
- ğŸ’¬ **Discord community:** https://discord.gg/arize
- ğŸ™ **GitHub:** https://github.com/Arize-ai/phoenix
- ğŸ“ **Tutorials:** https://docs.arize.com/phoenix/tutorials

---

## ğŸ› Troubleshooting

### Phoenix no inicia

```bash
# Verificar que el puerto 6006 estÃ© libre
lsof -i :6006

# Reiniciar container
docker-compose restart phoenix

# Ver logs
docker-compose logs -f phoenix
```

### No aparecen traces

**Causas comunes:**
1. âŒ `PHOENIX_ENABLE_INSTRUMENTATION=false` en .env
2. âŒ OpenAI API key invÃ¡lida
3. âŒ Phoenix host incorrecto

**SoluciÃ³n:**
```bash
# Verificar configuraciÃ³n
grep PHOENIX backend/.env

# Verificar que Phoenix estÃ© corriendo
curl http://localhost:6006/healthz

# Ver logs del backend
tail -f backend/logs/app.log
```

### Latencia alta en producciÃ³n

Phoenix agrega ~5-10ms de overhead. Si es crÃ­tico:
- Usar sampling (10% de traces)
- EnvÃ­o asÃ­ncrono de traces
- Aumentar batch size

---

**ğŸ‰ Â¡Listo! Ahora tienes observabilidad completa de tus LLMs con Phoenix.**

**ğŸ“Š Dashboard:** http://localhost:6006
