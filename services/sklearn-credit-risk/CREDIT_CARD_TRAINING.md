# üí≥ Entrenamiento del Modelo de Tarjetas de Cr√©dito

Gu√≠a completa para entrenar el modelo de predicci√≥n de default en tarjetas de cr√©dito usando los datasets `train.csv` y `test.csv`.

## üìä Descripci√≥n de los Datos

### Archivos Disponibles
- **`train.csv`**: Datos de entrenamiento (~45,000 registros)
- **`test.csv`**: Datos de prueba para evaluaci√≥n

### Columnas del Dataset

| Columna | Tipo | Descripci√≥n |
|---|---|---|
| `customer_id` | str | ID √∫nico del cliente |
| `name` | str | Nombre del cliente |
| `age` | int | Edad del cliente |
| `gender` | str | G√©nero (M/F) |
| `owns_car` | str | Posee coche (Y/N) |
| `owns_house` | str | Posee casa (Y/N) |
| `no_of_children` | float | N√∫mero de hijos |
| `net_yearly_income` | float | Ingresos anuales netos |
| `no_of_days_employed` | float | D√≠as empleado |
| `occupation_type` | str | Tipo de ocupaci√≥n |
| `total_family_members` | float | Miembros de la familia |
| `migrant_worker` | float | Trabajador migrante (0/1) |
| `yearly_debt_payments` | float | Pagos anuales de deuda |
| `credit_limit` | float | L√≠mite de cr√©dito |
| `credit_limit_used(%)` | float | Porcentaje de cr√©dito usado |
| `credit_score` | float | Score crediticio |
| `prev_defaults` | int | Defaults previos |
| `default_in_last_6months` | int | Default en √∫ltimos 6 meses |
| **`credit_card_default`** | **int** | **Target: 0=no default, 1=default** |

## üöÄ C√≥mo Entrenar el Modelo

### Opci√≥n 1: Ejecutar Script Completo

```bash
# 1. Navegar al directorio
cd services/sklearn-credit-risk

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar entrenamiento
python train_credit_card_model.py
```

### Opci√≥n 2: Usar Python Interactivo

```python
from train_credit_card_model import CreditCardModelTrainer

# Crear trainer
trainer = CreditCardModelTrainer(
    train_path="train.csv",
    test_path="test.csv"
)

# Ejecutar pipeline completo
results = trainer.run_full_pipeline(
    hyperparameter_tuning=False  # True para optimizar hiperpar√°metros
)

print(f"AUC-ROC: {results['metrics']['auc_roc']:.4f}")
print(f"Version: {results['version']}")
```

### Opci√≥n 3: Paso a Paso

```python
from train_credit_card_model import CreditCardModelTrainer

trainer = CreditCardModelTrainer("train.csv", "test.csv")

# 1. Cargar datos
trainer.load_data()

# 2. An√°lisis exploratorio
trainer.exploratory_analysis()

# 3. Preprocesamiento
trainer.preprocess_data()

# 4. Entrenar modelo
trainer.train_model(hyperparameter_tuning=True)

# 5. Entrenar detector de fraude
trainer.train_fraud_detector()

# 6. Evaluar
metrics = trainer.evaluate_model()

# 7. Guardar
version = trainer.save_models()
```

## üîß Procesamiento Aplicado

### 1. Limpieza de Datos
- ‚úÖ Eliminaci√≥n de columnas no predictivas (`customer_id`, `name`)
- ‚úÖ Imputaci√≥n de valores faltantes (mediana para num√©ricos, moda para categ√≥ricos)
- ‚úÖ Codificaci√≥n de variables categ√≥ricas con LabelEncoder

### 2. Feature Engineering

El script crea autom√°ticamente las siguientes features derivadas:

| Feature | F√≥rmula | Descripci√≥n |
|---|---|---|
| `credit_utilization_ratio` | `credit_limit_used(%) / 100` | Ratio de utilizaci√≥n normalizado |
| `debt_to_income_ratio` | `yearly_debt_payments / net_yearly_income` | Ratio deuda/ingresos |
| `credit_used_amount` | `credit_limit * credit_limit_used(%) / 100` | Monto usado absoluto |
| `income_per_family_member` | `net_yearly_income / total_family_members` | Ingreso per c√°pita |
| `years_employed` | `no_of_days_employed / 365` | A√±os de empleo |
| `high_risk_indicator` | `(prev_defaults > 0) OR (default_in_last_6months > 0) OR (credit_score < 600)` | Indicador de alto riesgo |

### 3. Modelos Entrenados

#### Modelo Principal: Gradient Boosting Classifier
```python
GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5,
    min_samples_split=5,
    min_samples_leaf=2,
    subsample=0.8,
    random_state=42
)
```
- **Calibrado** con `CalibratedClassifierCV` (m√©todo sigmoid)
- **Probabilidades confiables** para decisiones

#### Detector de Fraude: Isolation Forest
```python
IsolationForest(
    n_estimators=100,
    contamination=0.05,
    random_state=42
)
```
- Detecta anomal√≠as en patrones de solicitud
- Identifica ~5% de casos sospechosos

## üìä M√©tricas de Evaluaci√≥n

El script proporciona las siguientes m√©tricas en el conjunto de test:

| M√©trica | Descripci√≥n | Objetivo |
|---|---|---|
| **Accuracy** | Precisi√≥n general | >0.85 |
| **Precision** | Precisi√≥n en clase positiva | >0.75 |
| **Recall** | Cobertura de defaults | >0.70 |
| **F1-Score** | Balance precision/recall | >0.72 |
| **AUC-ROC** | √Årea bajo curva ROC | >0.80 |
| **AUC-PR** | √Årea bajo Precision-Recall | >0.70 |
| **Brier Score** | Calibraci√≥n de probabilidades | <0.15 |
| **Log Loss** | P√©rdida logar√≠tmica | <0.50 |

## üìà Ejemplo de Output

```
================================================================================
üöÄ INICIANDO PIPELINE COMPLETO DE ENTRENAMIENTO
================================================================================

================================================================================
üìÇ CARGANDO DATOS
================================================================================
‚úÖ Train: 45530 filas, 19 columnas
‚úÖ Test: 11383 filas, 19 columnas
‚úÖ Target (train): {0: 40234, 1: 5296}
   - Default rate: 11.63%

================================================================================
üîç AN√ÅLISIS EXPLORATORIO
================================================================================

üìä Informaci√≥n de columnas:
Columnas: ['customer_id', 'name', 'age', 'gender', ...]

‚úÖ No hay valores faltantes

üìà Estad√≠sticas descriptivas (num√©ricas):
              age  no_of_children  net_yearly_income  ...
count   45530.00        45530.00          45530.00  ...
mean       43.98            0.42         168787.92  ...
std         8.61            0.74         237123.45  ...

üéØ Distribuci√≥n del target:
   - No Default (0): 88.37%
   - Default (1): 11.63%

üîó Top 10 correlaciones con target:
credit_card_default              1.000000
prev_defaults                    0.456789
default_in_last_6months          0.398765
credit_limit_used(%)             0.287654
...

================================================================================
üîß PREPROCESAMIENTO DE DATOS
================================================================================

üóëÔ∏è Eliminando columnas no predictivas...
üîß Manejando valores faltantes...
   - no_of_children: imputado con mediana (0.00)
   - occupation_type: imputado con moda (Unknown)

üî§ Codificando variables categ√≥ricas...
   - gender: 2 categor√≠as
   - occupation_type: 15 categor√≠as

‚öôÔ∏è Feature Engineering...
   ‚úÖ Features creadas:
      - credit_utilization_ratio
      - debt_to_income_ratio
      - credit_used_amount
      - income_per_family_member
      - years_employed
      - high_risk_indicator

‚úÖ Preprocesamiento completado:
   - Features: 23
   - Train samples: 45530
   - Test samples: 11383

================================================================================
üéØ ENTRENAMIENTO DEL MODELO
================================================================================

üéØ Entrenando con par√°metros por defecto...
      Iter       Train Loss   Remaining Time 
         1           0.3456            12.34s
        50           0.1234             8.45s
       100           0.0987             4.23s
       150           0.0856             2.11s
       200           0.0789             0.00s

üìê Calibrando probabilidades...
‚úÖ Modelo entrenado y calibrado

üîç Entrenando detector de fraude/anomal√≠as...
‚úÖ Detector de fraude entrenado (contamination=0.05)

================================================================================
üìä EVALUACI√ìN DEL MODELO
================================================================================

üìà M√©tricas de Clasificaci√≥n:
   - Accuracy: 0.9234
   - Precision: 0.8567
   - Recall: 0.7845
   - F1-Score: 0.8189
   - AUC-ROC: 0.8923
   - AUC-PR: 0.7654
   - Brier Score: 0.0987
   - Log Loss: 0.2345

üìä Matriz de Confusi√≥n:
   TN: 10123  |  FP:   345
   FN:   567  |  TP:   348

üìã Classification Report:
              precision    recall  f1-score   support
  No Default       0.95      0.97      0.96     10468
     Default       0.86      0.78      0.82       915
    accuracy                           0.92     11383

üîù Top 15 Features m√°s importantes:
    1. prev_defaults                  : 0.1845
    2. credit_score                   : 0.1567
    3. default_in_last_6months        : 0.1234
    4. credit_utilization_ratio       : 0.0987
    5. debt_to_income_ratio           : 0.0856
    6. high_risk_indicator            : 0.0745
    7. credit_limit_used(%)           : 0.0654
    8. yearly_debt_payments           : 0.0543
    9. net_yearly_income              : 0.0432
   10. age                            : 0.0321
   11. years_employed                 : 0.0298
   12. credit_used_amount             : 0.0276
   13. income_per_family_member       : 0.0234
   14. total_family_members           : 0.0198
   15. no_of_children                 : 0.0167

üîç Evaluaci√≥n del Detector de Fraude:
   - Anomal√≠as detectadas: 569 (5.00%)

================================================================================
üíæ GUARDANDO MODELOS
================================================================================
‚úÖ Modelo guardado: ./models/credit_card_model_v20241028_185500.pkl
‚úÖ Detector de fraude guardado: ./models/fraud_detector_v20241028_185500.pkl
‚úÖ Label encoders guardados: ./models/label_encoders_v20241028_185500.pkl
‚úÖ Metadata guardada: ./models/metadata_v20241028_185500.pkl

üéâ Todos los modelos guardados en: ./models
   Version: 20241028_185500

================================================================================
‚úÖ PIPELINE COMPLETADO EXITOSAMENTE
================================================================================
‚è±Ô∏è  Tiempo total: 123.45 segundos
üì¶ Version: 20241028_185500
üéØ AUC-ROC: 0.8923
üìä F1-Score: 0.8189
================================================================================
```

## üìÅ Archivos Generados

Despu√©s del entrenamiento se crean 4 archivos en `./models/`:

```
models/
‚îú‚îÄ‚îÄ credit_card_model_v20241028_185500.pkl      # Modelo principal (GradientBoosting + Calibraci√≥n)
‚îú‚îÄ‚îÄ fraud_detector_v20241028_185500.pkl         # Detector de fraude (IsolationForest)
‚îú‚îÄ‚îÄ label_encoders_v20241028_185500.pkl         # Encoders para variables categ√≥ricas
‚îî‚îÄ‚îÄ metadata_v20241028_185500.pkl               # Metadata (features, m√©tricas, etc)
```

## üîÑ Integraci√≥n con el Servicio

### Cargar Modelo Entrenado en main.py

```python
import joblib

# Cargar modelo entrenado
credit_risk_model = joblib.load("models/credit_card_model_v20241028_185500.pkl")
fraud_detector = joblib.load("models/fraud_detector_v20241028_185500.pkl")
label_encoders = joblib.load("models/label_encoders_v20241028_185500.pkl")
metadata = joblib.load("models/metadata_v20241028_185500.pkl")

print(f"Modelo cargado: {metadata['version']}")
print(f"AUC-ROC: {metadata['metrics']['auc_roc']:.4f}")
```

### Hacer Predicci√≥n

```python
import pandas as pd
import numpy as np

# Preparar datos de entrada (mismo preprocesamiento)
def prepare_input(data_dict):
    # Aplicar mismo feature engineering
    df = pd.DataFrame([data_dict])
    
    # Codificar categ√≥ricas
    for col, encoder in label_encoders.items():
        if col in df.columns:
            df[col] = encoder.transform(df[col].astype(str))
    
    # Feature engineering
    df['credit_utilization_ratio'] = df['credit_limit_used(%)'] / 100.0
    df['debt_to_income_ratio'] = df['yearly_debt_payments'] / df['net_yearly_income']
    df['credit_used_amount'] = (df['credit_limit'] * df['credit_limit_used(%)']) / 100.0
    df['income_per_family_member'] = df['net_yearly_income'] / df['total_family_members']
    df['years_employed'] = df['no_of_days_employed'] / 365.0
    df['high_risk_indicator'] = (
        (df['prev_defaults'] > 0) | 
        (df['default_in_last_6months'] > 0) |
        (df['credit_score'] < 600)
    ).astype(int)
    
    return df[metadata['feature_names']]

# Ejemplo de predicci√≥n
customer_data = {
    'age': 35,
    'gender': 'M',
    'owns_car': 'Y',
    'owns_house': 'Y',
    'no_of_children': 2,
    'net_yearly_income': 150000,
    'no_of_days_employed': 2000,
    'occupation_type': 'Core staff',
    'total_family_members': 4,
    'migrant_worker': 0,
    'yearly_debt_payments': 25000,
    'credit_limit': 50000,
    'credit_limit_used(%)': 65,
    'credit_score': 720,
    'prev_defaults': 0,
    'default_in_last_6months': 0
}

X = prepare_input(customer_data)
probability = credit_risk_model.predict_proba(X)[0][1]
prediction = int(probability > 0.5)

print(f"Probabilidad de default: {probability:.2%}")
print(f"Predicci√≥n: {'Default' if prediction else 'No Default'}")
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Hyperparameter Tuning

```python
# Activar b√∫squeda de hiperpar√°metros (tarda m√°s tiempo)
results = trainer.run_full_pipeline(hyperparameter_tuning=True)
```

Par√°metros explorados:
- `n_estimators`: [100, 200]
- `learning_rate`: [0.05, 0.1]
- `max_depth`: [3, 5, 7]
- `min_samples_split`: [2, 5]
- `min_samples_leaf`: [1, 2]
- `subsample`: [0.8, 1.0]

### Ajustar Contaminaci√≥n de Fraude

```python
# Si esperas m√°s fraude (10%)
trainer.train_fraud_detector(contamination=0.10)
```

## üéØ Pr√≥ximos Pasos

1. ‚úÖ Ejecutar `python train_credit_card_model.py`
2. ‚úÖ Revisar m√©tricas en consola
3. ‚úÖ Verificar modelos en `./models/`
4. üìù Actualizar `main.py` para cargar modelo entrenado
5. üß™ Probar predicciones con datos reales
6. üöÄ Desplegar servicio
7. üìä Monitorear performance en producci√≥n

## üÜò Troubleshooting

### Error: "FileNotFoundError: train.csv"
**Soluci√≥n**: Aseg√∫rate de estar en el directorio correcto:
```bash
cd services/sklearn-credit-risk
ls train.csv test.csv  # Verificar archivos
```

### Warning: "Low AUC-ROC"
**Soluciones**:
- Activar `hyperparameter_tuning=True`
- Verificar balance de clases
- Revisar calidad de features

### Error: "Memory Error"
**Soluci√≥n**: Reducir `n_estimators` o usar menos datos:
```python
# Usar subset de datos
df_train = df_train.sample(n=10000, random_state=42)
```

## üìö Recursos

- [Gradient Boosting Documentation](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)
- [Calibration Guide](https://scikit-learn.org/stable/modules/calibration.html)
- [Isolation Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)
