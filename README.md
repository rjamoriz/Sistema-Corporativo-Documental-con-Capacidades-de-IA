# ğŸš€ FinancIA 2030 - Sistema Corporativo Documental con IA

![Estado](https://img.shields.io/badge/Estado-%20Production%20Ready-brightgreen) ![VersiÃ³n](https://img.shields.io/badge/VersiÃ³n-1.0.0-blue) ![RFP Coverage](https://img.shields.io/badge/RFP%20Coverage-100%25-gold) ![License](https://img.shields.io/badge/License-Proprietary-red)

**Plataforma enterprise de gestiÃ³n documental inteligente** con capacidades avanzadas de IA para procesamiento, clasificaciÃ³n, bÃºsqueda semÃ¡ntica y anÃ¡lisis de riesgo. DiseÃ±ada para entornos financieros y corporativos con requisitos estrictos de cumplimiento normativo.

**Links rÃ¡pidos:** [ğŸš€ Inicio rÃ¡pido](#-inicio-rÃ¡pido) | [ğŸ“š DocumentaciÃ³n](docs/) | [ğŸ—ï¸ Arquitectura](#-arquitectura-de-la-soluciÃ³n) | [ğŸ¯ CaracterÃ­sticas](#-caracterÃ­sticas-principales)

---

## ğŸ“‹ Tabla de Contenidos

- [Resumen Ejecutivo](#-resumen-ejecutivo)
- [Arquitectura de la SoluciÃ³n](#-arquitectura-de-la-soluciÃ³n)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Funcionalidades Clave](#-funcionalidades-clave)
- [Stack TecnolÃ³gico](#-stack-tecnolÃ³gico)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [DocumentaciÃ³n](#-documentaciÃ³n)

---

## ğŸ¯ Resumen Ejecutivo

**FinancIA 2030** es una soluciÃ³n end-to-end de gestiÃ³n documental corporativa que integra:

- **ğŸ¤– Inteligencia Artificial**: OCR, NER, clasificaciÃ³n automÃ¡tica, embeddings semÃ¡nticos y RAG
- **ğŸ” BÃºsqueda HÃ­brida**: CombinaciÃ³n de bÃºsqueda lÃ©xica (BM25) y semÃ¡ntica (vectores)
- **âš–ï¸ Cumplimiento Normativo**: EU AI Act 2024, GDPR/LOPDGDD, NIS2, ISO 27001/27701/42001
- **ğŸ“Š AnÃ¡lisis de Riesgo**: Scoring multidimensional con explicabilidad total
- **ğŸ” Seguridad Enterprise**: AutenticaciÃ³n SSO/MFA, cifrado end-to-end, auditorÃ­a completa
- **ğŸ“ˆ Observabilidad**: Monitoreo de LLMs con Arize Phoenix, mÃ©tricas operativas en tiempo real

### Casos de Uso

âœ… **GestiÃ³n de contratos** - ClasificaciÃ³n, extracciÃ³n de clÃ¡usulas, alertas de vencimiento  
âœ… **Compliance financiero** - ValidaciÃ³n automÃ¡tica de documentaciÃ³n regulatoria  
âœ… **AnÃ¡lisis de riesgo** - Scoring de documentos con explicabilidad  
âœ… **BÃºsqueda inteligente** - RAG conversacional con citaciÃ³n de fuentes  
âœ… **Procesamiento masivo** - IngestiÃ³n y OCR de miles de documentos  
âœ… **AuditorÃ­a y trazabilidad** - Logs inmutables de todas las operaciones

---

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

### Vista de Alto Nivel

```mermaid
graph TB
    subgraph "ğŸŒ Capa de PresentaciÃ³n"
        UI[React Frontend<br/>TypeScript + Vite]
    end
    
    subgraph "ğŸ”’ API Gateway"
        API[FastAPI Gateway<br/>Auth + Rate Limiting]
    end
    
    subgraph "âš™ï¸ Microservicios Core"
        DOC[ğŸ“„ Document Service<br/>IngestiÃ³n + Procesamiento]
        SEARCH[ğŸ” Search Service<br/>HÃ­brida: LÃ©xica + SemÃ¡ntica]
        RAG[ğŸ¤– RAG Service<br/>Asistente Conversacional]
        ML[ğŸ§  ML Service<br/>ClasificaciÃ³n + NER]
    end
    
    subgraph "ğŸ“Š Servicios de Negocio"
        RISK[âš ï¸ Risk Analysis<br/>Scoring Multidimensional]
        COMP[âš–ï¸ Compliance<br/>Motor de Reglas]
        SYNTH[ğŸ§¬ Synthetic Data<br/>GeneraciÃ³n de Datos]
    end
    
    subgraph "ğŸ’¾ Capa de Datos"
        PG[(PostgreSQL<br/>+pgvector)]
        OS[(OpenSearch<br/>BM25)]
        REDIS[(Redis<br/>Cache)]
        MINIO[(MinIO<br/>S3 Storage)]
        QDRANT[(Qdrant<br/>Vector DB)]
    end
    
    subgraph "ğŸ”§ Infraestructura"
        CELERY[Celery Workers<br/>Procesamiento Async]
        PHOENIX[Arize Phoenix<br/>LLM Observability]
    end
    
    UI -->|HTTPS| API
    API --> DOC
    API --> SEARCH
    API --> RAG
    API --> ML
    API --> RISK
    API --> COMP
    API --> SYNTH
    
    DOC --> PG
    DOC --> MINIO
    DOC --> CELERY
    
    SEARCH --> OS
    SEARCH --> QDRANT
    
    RAG --> QDRANT
    RAG --> PG
    RAG --> PHOENIX
    
    ML --> PG
    ML --> REDIS
    
    RISK --> PG
    COMP --> PG
    SYNTH --> PG
    
    CELERY --> REDIS
    
    style UI fill:#4FC3F7,stroke:#0277BD,stroke-width:3px,color:#000
    style API fill:#FFB74D,stroke:#E65100,stroke-width:3px,color:#000
    style DOC fill:#BA68C8,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style SEARCH fill:#9575CD,stroke:#4527A0,stroke-width:2px,color:#fff
    style RAG fill:#7E57C2,stroke:#311B92,stroke-width:2px,color:#fff
    style ML fill:#5C6BC0,stroke:#1A237E,stroke-width:2px,color:#fff
    style RISK fill:#66BB6A,stroke:#1B5E20,stroke-width:2px,color:#000
    style COMP fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#000
    style SYNTH fill:#81C784,stroke:#388E3C,stroke-width:2px,color:#000
    style PG fill:#42A5F5,stroke:#0D47A1,stroke-width:2px,color:#fff
    style OS fill:#26C6DA,stroke:#006064,stroke-width:2px,color:#000
    style REDIS fill:#EF5350,stroke:#B71C1C,stroke-width:2px,color:#fff
    style MINIO fill:#FF7043,stroke:#BF360C,stroke-width:2px,color:#fff
    style QDRANT fill:#AB47BC,stroke:#4A148C,stroke-width:2px,color:#fff
    style CELERY fill:#FFA726,stroke:#E65100,stroke-width:2px,color:#000
    style PHOENIX fill:#EC407A,stroke:#880E4F,stroke-width:2px,color:#fff
```

### Pipeline de Procesamiento Documental

```mermaid
graph LR
    A[ğŸ“¥ Upload] -->|ValidaciÃ³n| B[ğŸ” Ingest]
    B -->|OCR| C[ğŸ“ Transform]
    C -->|ExtracciÃ³n| D[ğŸ”¬ Extract]
    D -->|NER + Metadata| E[ğŸ·ï¸ Classify]
    E -->|ML Model| F[ğŸ“Š Index]
    F -->|Dual Index| G[ğŸ” Search/RAG]
    D -->|ValidaciÃ³n| H[âš–ï¸ Compliance]
    D -->|AnÃ¡lisis| I[âš ï¸ Risk Scoring]
    
    style A fill:#4FC3F7,stroke:#0277BD,stroke-width:3px,color:#000
    style B fill:#BA68C8,stroke:#6A1B9A,stroke-width:3px,color:#fff
    style C fill:#9575CD,stroke:#4527A0,stroke-width:3px,color:#fff
    style D fill:#7E57C2,stroke:#311B92,stroke-width:3px,color:#fff
    style E fill:#FFB74D,stroke:#E65100,stroke-width:3px,color:#000
    style F fill:#66BB6A,stroke:#1B5E20,stroke-width:3px,color:#000
    style G fill:#26C6DA,stroke:#006064,stroke-width:3px,color:#000
    style H fill:#EC407A,stroke:#880E4F,stroke-width:3px,color:#fff
    style I fill:#FFA726,stroke:#E65100,stroke-width:3px,color:#000
```

### Arquitectura de Microservicios (Vista Detallada)

```mermaid
graph TB
    subgraph "Frontend Layer"
        FE[React SPA<br/>Port 3000]
    end
    
    subgraph "Backend Services - Port 8000"
        direction TB
        AUTH[ğŸ” Auth Module<br/>JWT + SSO]
        DOCS[ğŸ“„ Documents API<br/>/api/v1/documents]
        SRCH[ğŸ” Search API<br/>/api/v1/search]
        RAGAPI[ğŸ¤– RAG API<br/>/api/v1/rag]
        MLAPI[ğŸ§  ML API<br/>/api/v1/ml]
        RISKAPI[âš ï¸ Risk API<br/>/api/v1/risk]
        COMPAPI[âš–ï¸ Compliance API<br/>/api/v1/compliance]
        SYNTHAPI[ğŸ§¬ Synthetic API<br/>/api/v1/synthetic]
        GRAPHQL[ğŸ“Š GraphQL API<br/>/graphql]
    end
    
    subgraph "Processing Layer"
        WORKER1[Celery Worker 1<br/>OCR + Transform]
        WORKER2[Celery Worker 2<br/>ML + Classification]
        WORKER3[Celery Worker 3<br/>Embeddings + Index]
    end
    
    subgraph "Data Layer"
        direction LR
        DB1[(PostgreSQL<br/>Metadata + Users)]
        DB2[(OpenSearch<br/>Full-Text Search)]
        DB3[(Qdrant<br/>Vector Search)]
        DB4[(Redis<br/>Queue + Cache)]
        DB5[(MinIO<br/>Object Storage)]
    end
    
    FE -->|REST/GraphQL| AUTH
    AUTH --> DOCS
    AUTH --> SRCH
    AUTH --> RAGAPI
    AUTH --> MLAPI
    AUTH --> RISKAPI
    AUTH --> COMPAPI
    AUTH --> SYNTHAPI
    AUTH --> GRAPHQL
    
    DOCS --> WORKER1
    MLAPI --> WORKER2
    SRCH --> WORKER3
    
    WORKER1 --> DB4
    WORKER2 --> DB4
    WORKER3 --> DB4
    
    DOCS --> DB1
    DOCS --> DB5
    SRCH --> DB2
    SRCH --> DB3
    RAGAPI --> DB3
    MLAPI --> DB1
    RISKAPI --> DB1
    COMPAPI --> DB1
    
    style FE fill:#4FC3F7,stroke:#0277BD,stroke-width:3px,color:#000
    style AUTH fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style DOCS fill:#BA68C8,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style SRCH fill:#9575CD,stroke:#4527A0,stroke-width:2px,color:#fff
    style RAGAPI fill:#7E57C2,stroke:#311B92,stroke-width:2px,color:#fff
    style MLAPI fill:#5C6BC0,stroke:#1A237E,stroke-width:2px,color:#fff
    style RISKAPI fill:#66BB6A,stroke:#1B5E20,stroke-width:2px,color:#000
    style COMPAPI fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#000
    style SYNTHAPI fill:#81C784,stroke:#388E3C,stroke-width:2px,color:#000
    style GRAPHQL fill:#26C6DA,stroke:#006064,stroke-width:2px,color:#000
    style WORKER1 fill:#FFA726,stroke:#E65100,stroke-width:2px,color:#000
    style WORKER2 fill:#FFB74D,stroke:#EF6C00,stroke-width:2px,color:#000
    style WORKER3 fill:#FFCC80,stroke:#F57C00,stroke-width:2px,color:#000
    style DB1 fill:#42A5F5,stroke:#0D47A1,stroke-width:2px,color:#fff
    style DB2 fill:#26C6DA,stroke:#006064,stroke-width:2px,color:#000
    style DB3 fill:#AB47BC,stroke:#4A148C,stroke-width:2px,color:#fff
    style DB4 fill:#EF5350,stroke:#B71C1C,stroke-width:2px,color:#fff
    style DB5 fill:#FF7043,stroke:#BF360C,stroke-width:2px,color:#fff
```

### Arquitectura v2.0 - Quantum & GPU Enhancement

```mermaid
graph TB
    subgraph "ğŸŒ Sistema Actual v1.0"
        APP[App Principal<br/>Backend + Frontend]
        DB[(Bases de Datos<br/>PostgreSQL + OpenSearch + Qdrant)]
    end
    
    subgraph "ğŸ® GPU Acceleration Layer"
        GPU[GPU Embedding Service<br/>Puerto 8001]
        FAISS[FAISS-GPU<br/>Vector Search]
    end
    
    subgraph "âš›ï¸ Quantum Computing Layer"
        DWAVE[D-Wave Service<br/>Puerto 8002<br/>QUBO + Simulated Annealing]
        IBM[IBM Qiskit Service<br/>Puerto 8003<br/>QAOA + Circuits]
        NVIDIA[NVIDIA cuQuantum Service<br/>Puerto 8004<br/>GPU Simulation]
    end
    
    subgraph "ğŸ¤– Enhanced AI Layer"
        RAG[RAG Enhanced Service<br/>Puerto 8005<br/>OpenAI + Anthropic]
    end
    
    subgraph "ğŸ“Š Monitoring Layer"
        PROM[Prometheus<br/>Puerto 9090]
        GRAF[Grafana<br/>Puerto 3001]
    end
    
    APP -.->|Opcional| GPU
    APP -.->|Opcional| DWAVE
    APP -.->|Opcional| IBM
    APP -.->|Opcional| NVIDIA
    APP -.->|Opcional| RAG
    
    GPU --> FAISS
    RAG --> GPU
    
    GPU --> PROM
    DWAVE --> PROM
    IBM --> PROM
    NVIDIA --> PROM
    RAG --> PROM
    
    PROM --> GRAF
    
    style APP fill:#4FC3F7,stroke:#0277BD,stroke-width:3px,color:#000
    style GPU fill:#FFB74D,stroke:#E65100,stroke-width:3px,color:#000
    style FAISS fill:#FFA726,stroke:#EF6C00,stroke-width:2px,color:#000
    style DWAVE fill:#BA68C8,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style IBM fill:#9575CD,stroke:#4527A0,stroke-width:2px,color:#fff
    style NVIDIA fill:#7E57C2,stroke:#311B92,stroke-width:2px,color:#fff
    style RAG fill:#66BB6A,stroke:#1B5E20,stroke-width:2px,color:#000
    style PROM fill:#EF5350,stroke:#B71C1C,stroke-width:2px,color:#fff
    style GRAF fill:#EC407A,stroke:#880E4F,stroke-width:2px,color:#fff
```

**CaracterÃ­sticas v2.0:**
- âš¡ **GPU Acceleration**: Embeddings 10-20Ã— mÃ¡s rÃ¡pidos
- âš›ï¸ **Quantum Computing**: OptimizaciÃ³n QUBO para deduplicaciÃ³n
- ğŸ§  **Quantum ML**: ClasificaciÃ³n con circuitos cuÃ¡nticos
- ğŸ¤– **Enhanced RAG**: LLMs con trazabilidad 100%
- ğŸ“Š **Monitoring**: Prometheus + Grafana opensource
- ğŸ”Œ **Modular**: Servicios independientes, no afectan app actual

---

## ğŸ“ Estructura del Proyecto

```
Sistema-Corporativo-Documental-con-Capacidades-de-IA/
â”œâ”€â”€ ğŸ“‚ backend/                          # Backend existente (FastAPI)
â”‚   â”œâ”€â”€ api/                             # Endpoints REST
â”‚   â”œâ”€â”€ core/                            # ConfiguraciÃ³n y seguridad
â”‚   â”œâ”€â”€ models/                          # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ services/                        # LÃ³gica de negocio
â”‚   â”œâ”€â”€ ml/                              # Modelos ML
â”‚   â””â”€â”€ main.py                          # Punto de entrada
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/                         # Frontend existente (React + TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                  # Componentes React
â”‚   â”‚   â”œâ”€â”€ pages/                       # PÃ¡ginas
â”‚   â”‚   â”œâ”€â”€ services/                    # API clients
â”‚   â”‚   â””â”€â”€ App.tsx                      # App principal
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ğŸ“‚ services/                         # âœ¨ NUEVOS SERVICIOS v2.0
â”‚   â”œâ”€â”€ ğŸ® gpu-embedding/               # GPU Embedding Service
â”‚   â”‚   â”œâ”€â”€ main.py                      # FastAPI service
â”‚   â”‚   â”œâ”€â”€ Dockerfile                   # CUDA 12.1 + PyTorch
â”‚   â”‚   â”œâ”€â”€ requirements.txt             # Dependencias GPU
â”‚   â”‚   â”œâ”€â”€ README.md                    # DocumentaciÃ³n
â”‚   â”‚   â””â”€â”€ .env.example                 # ConfiguraciÃ³n
â”‚   â”‚
â”‚   â”œâ”€â”€ âš›ï¸ quantum-dwave/               # Quantum D-Wave Service
â”‚   â”‚   â”œâ”€â”€ main.py                      # QUBO + Simulated Annealing
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt             # D-Wave Ocean SDK
â”‚   â”‚   â””â”€â”€ .env.example
â”‚   â”‚
â”‚   â”œâ”€â”€ âš›ï¸ quantum-ibm/                 # Quantum IBM Qiskit Service
â”‚   â”‚   â”œâ”€â”€ main.py                      # QAOA + Circuits
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt             # Qiskit + Aer
â”‚   â”‚   â””â”€â”€ .env.example
â”‚   â”‚
â”‚   â”œâ”€â”€ âš›ï¸ quantum-nvidia/              # Quantum NVIDIA cuQuantum Service
â”‚   â”‚   â”œâ”€â”€ main.py                      # GPU Quantum Simulation
â”‚   â”‚   â”œâ”€â”€ Dockerfile                   # CUDA + Qiskit-Aer-GPU
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ .env.example
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– rag-enhanced/                # RAG Enhanced Service
â”‚   â”‚   â”œâ”€â”€ main.py                      # RAG + LLMs
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt             # LangChain + OpenAI + Anthropic
â”‚   â”‚   â””â”€â”€ .env.example
â”‚   â”‚
â”‚   â””â”€â”€ README.md                        # ğŸ“š README consolidado servicios
â”‚
â”œâ”€â”€ ğŸ“‚ monitoring/                       # âœ¨ MONITOREO (Opensource)
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml               # ConfiguraciÃ³n Prometheus
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ datasources/
â”‚           â””â”€â”€ prometheus.yml           # Datasource Grafana
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                             # ğŸ“š DOCUMENTACIÃ“N
â”‚   â”œâ”€â”€ ARCHITECTURE.md                  # Arquitectura tÃ©cnica
â”‚   â”œâ”€â”€ QUANTUM_GPU_ENHANCEMENT_PLAN.md  # âœ¨ Plan v2.0 completo
â”‚   â”œâ”€â”€ IMPLEMENTATION_GUIDE_V2.md       # âœ¨ GuÃ­a de implementaciÃ³n
â”‚   â”œâ”€â”€ TESTING_GUIDE.md                 # âœ¨ GuÃ­a de testing
â”‚   â”œâ”€â”€ API_DOCUMENTATION.md             # DocumentaciÃ³n API
â”‚   â””â”€â”€ DEPLOYMENT.md                    # GuÃ­a de despliegue
â”‚
â”œâ”€â”€ ğŸ“‚ infrastructure/                   # Infraestructura
â”‚   â””â”€â”€ docker/                          # Configuraciones Docker
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml                # Compose app principal
â”œâ”€â”€ ğŸ“„ docker-compose.quantum-gpu.yml    # âœ¨ Compose servicios v2.0
â”œâ”€â”€ ğŸ“„ README.md                         # Este archivo
â””â”€â”€ ğŸ“„ .env.example                      # Variables de entorno

Leyenda:
ğŸ“‚ Carpeta existente
âœ¨ Nuevo en v2.0
ğŸ® GPU Service
âš›ï¸ Quantum Service
ğŸ¤– AI Service
ğŸ“š DocumentaciÃ³n
```

**EstadÃ­sticas del Proyecto:**
- **Servicios v1.0:** 1 aplicaciÃ³n monolÃ­tica
- **Servicios v2.0:** +5 microservicios modulares
- **LÃ­neas de cÃ³digo v2.0:** ~4,500+
- **DocumentaciÃ³n v2.0:** ~3,000+ lÃ­neas
- **Endpoints API v2.0:** +25 nuevos endpoints
- **Frameworks cuÃ¡nticos:** 3 (D-Wave, IBM Qiskit, NVIDIA cuQuantum)

---

## ğŸ—„ï¸ Arquitectura DataStax Astra DB - Vector Search

### Diagrama de Componente

```mermaid
graph TB
    subgraph "ğŸ“± Cliente"
        USER[Usuario/AplicaciÃ³n]
    end
    
    subgraph "ğŸ¯ API Layer"
        API[FastAPI Service<br/>Puerto 8006]
        CACHE[Redis Cache<br/>Consultas Frecuentes]
    end
    
    subgraph "ğŸ”„ Processing Layer"
        DOC[Document Processor<br/>PDF, DOCX, TXT]
        CHUNK[Text Chunker<br/>Overlapping Windows]
        EMB[Embedding Generator<br/>OpenAI/Cohere/BERT]
    end
    
    subgraph "ğŸ® GPU Integration"
        GPU[GPU Embedding Service<br/>Puerto 8001<br/>10-20x Faster]
    end
    
    subgraph "â˜ï¸ DataStax Astra DB Cloud"
        ASTRA[(Astra DB<br/>Vector Collection)]
        HNSW[HNSW Index<br/>ANN Search]
        META[Metadata Store<br/>JSON Fields]
    end
    
    subgraph "ğŸ“Š Monitoring"
        PROM[Prometheus<br/>MÃ©tricas]
        GRAF[Grafana<br/>Dashboards]
    end
    
    USER -->|Upload Doc| API
    USER -->|Search Query| API
    
    API -->|Check Cache| CACHE
    API -->|Process| DOC
    DOC -->|Extract Text| CHUNK
    CHUNK -->|Generate Embeddings| EMB
    
    EMB -.->|Optional GPU| GPU
    GPU -.->|Fast Embeddings| EMB
    
    EMB -->|Store Vector| ASTRA
    API -->|Vector Search| HNSW
    HNSW -->|ANN Results| API
    ASTRA -->|Metadata| META
    
    API -->|Metrics| PROM
    PROM -->|Visualize| GRAF
    
    API -->|Results + Cache| USER
    
    style USER fill:#4FC3F7,stroke:#0277BD,stroke-width:2px,color:#000
    style API fill:#66BB6A,stroke:#2E7D32,stroke-width:3px,color:#fff
    style CACHE fill:#FFA726,stroke:#EF6C00,stroke-width:2px,color:#000
    style DOC fill:#FFB74D,stroke:#F57C00,stroke-width:2px,color:#000
    style CHUNK fill:#FFCC80,stroke:#FB8C00,stroke-width:2px,color:#000
    style EMB fill:#FFD54F,stroke:#F9A825,stroke-width:2px,color:#000
    style GPU fill:#FF6F00,stroke:#E65100,stroke-width:3px,color:#fff
    style ASTRA fill:#7E57C2,stroke:#4527A0,stroke-width:3px,color:#fff
    style HNSW fill:#9575CD,stroke:#5E35B1,stroke-width:2px,color:#fff
    style META fill:#B39DDB,stroke:#673AB7,stroke-width:2px,color:#000
    style PROM fill:#EF5350,stroke:#C62828,stroke-width:2px,color:#fff
    style GRAF fill:#EC407A,stroke:#AD1457,stroke-width:2px,color:#fff
```

### Flujo de Datos

**IngestiÃ³n de Documentos:**
```
Usuario â†’ API â†’ Document Processor â†’ Text Chunker â†’ Embedding Generator â†’ [GPU Service] â†’ Astra DB
```

**BÃºsqueda SemÃ¡ntica:**
```
Query â†’ API â†’ [Cache Check] â†’ Embedding Generator â†’ [GPU Service] â†’ HNSW Search â†’ Ranking â†’ Usuario
```

---

## ğŸ§® Algoritmo HNSW (Hierarchical Navigable Small World)

### Fundamentos MatemÃ¡ticos

DataStax Astra DB utiliza el algoritmo **HNSW** para bÃºsquedas vectoriales eficientes (ANN - Approximate Nearest Neighbor).

#### 1. Estructura JerÃ¡rquica

El Ã­ndice HNSW construye una estructura de grafo multi-capa donde cada capa $l$ contiene un subconjunto de nodos:

$$
\text{Probabilidad de inserciÃ³n en capa } l: \quad P(l) = \frac{1}{2^l}
$$

**NÃºmero mÃ¡ximo de capas:**

$$
L_{max} = \lfloor -\ln(N) \cdot m_L \rfloor
$$

Donde:
- $N$ = nÃºmero total de vectores
- $m_L$ = factor de normalizaciÃ³n (tÃ­picamente $\frac{1}{\ln(2)}$)

#### 2. Distancia entre Vectores

Para vectores $\mathbf{v}_i, \mathbf{v}_j \in \mathbb{R}^d$, HNSW soporta mÃºltiples mÃ©tricas:

**Similitud Coseno (usada en Astra DB):**

$$
\text{similarity}(\mathbf{v}_i, \mathbf{v}_j) = \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{\|\mathbf{v}_i\| \|\mathbf{v}_j\|} = \frac{\sum_{k=1}^{d} v_{i,k} \cdot v_{j,k}}{\sqrt{\sum_{k=1}^{d} v_{i,k}^2} \cdot \sqrt{\sum_{k=1}^{d} v_{j,k}^2}}
$$

**Distancia Euclidiana:**

$$
d(\mathbf{v}_i, \mathbf{v}_j) = \|\mathbf{v}_i - \mathbf{v}_j\| = \sqrt{\sum_{k=1}^{d} (v_{i,k} - v_{j,k})^2}
$$

#### 3. Algoritmo de BÃºsqueda

**Entrada:** Vector query $\mathbf{q}$, nÃºmero de vecinos $K$

**Proceso:**

1. **Capa superior** ($l = L_{max}$): Encontrar punto de entrada $e_p$

$$
e_p = \arg\min_{v \in \text{Layer}_l} d(\mathbf{q}, \mathbf{v})
$$

2. **Descenso por capas** ($l = L_{max} \to 0$):

Para cada capa $l$:

$$
\text{candidates} = \{v \in \text{neighbors}(e_p) : d(\mathbf{q}, v) < d(\mathbf{q}, e_p)\}
$$

3. **BÃºsqueda en capa 0** (mÃ¡s densa):

Mantener lista de $K$ vecinos mÃ¡s cercanos:

$$
\text{result} = \text{top-K}\{\mathbf{v} \in \text{Layer}_0 : \text{similarity}(\mathbf{q}, \mathbf{v})\}
$$

#### 4. Complejidad Computacional

**Tiempo de bÃºsqueda:**

$$
O(\log N \cdot M)
$$

Donde:
- $N$ = nÃºmero de vectores en el Ã­ndice
- $M$ = nÃºmero mÃ¡ximo de conexiones por nodo (tÃ­picamente 16-32)

**ComparaciÃ³n con bÃºsqueda lineal:**

| MÃ©todo | Complejidad | Ejemplo (1M vectores) |
|--------|-------------|----------------------|
| **BÃºsqueda Lineal** | $O(N \cdot d)$ | ~1,000,000 comparaciones |
| **HNSW** | $O(\log N \cdot M)$ | ~300 comparaciones |
| **Speedup** | $\frac{N \cdot d}{\log N \cdot M}$ | **~3,300x mÃ¡s rÃ¡pido** |

#### 5. ParÃ¡metros de OptimizaciÃ³n

**Factor de construcciÃ³n** ($ef_{construction}$):

$$
ef_{construction} \geq K
$$

Controla la calidad del Ã­ndice durante construcciÃ³n.

**Factor de bÃºsqueda** ($ef_{search}$):

$$
ef_{search} \geq K
$$

Trade-off entre precisiÃ³n y velocidad:

$$
\text{Recall} \propto ef_{search}, \quad \text{Latency} \propto ef_{search}
$$

#### 6. Ejemplo PrÃ¡ctico

Para un sistema con:
- $N = 1,000,000$ documentos
- $d = 1536$ dimensiones (OpenAI ada-002)
- $M = 16$ conexiones
- $K = 5$ vecinos

**BÃºsqueda HNSW:**

$$
\text{Comparaciones} \approx \log_2(1,000,000) \cdot 16 \approx 320
$$

$$
\text{Latencia} \approx 1-5 \text{ ms}
$$

**vs BÃºsqueda Lineal:**

$$
\text{Comparaciones} = 1,000,000
$$

$$
\text{Latencia} \approx 500-1000 \text{ ms}
$$

**Mejora:** $\frac{1000}{5} = 200\text{x mÃ¡s rÃ¡pido}$

---

### ğŸ“Š Ventajas de HNSW en Astra DB

1. **Escalabilidad:** $O(\log N)$ permite millones de vectores
2. **PrecisiÃ³n:** Recall > 95% con configuraciÃ³n Ã³ptima
3. **Velocidad:** Latencias < 10ms para bÃºsquedas
4. **Memoria Eficiente:** Solo mantiene grafo, no matriz completa
5. **ActualizaciÃ³n DinÃ¡mica:** InserciÃ³n/eliminaciÃ³n en tiempo real

---

## âš›ï¸ Arquitectura Quantum ML - PennyLane

### Diagrama de Componente

```mermaid
graph TB
    subgraph "ğŸŒ Client Layer"
        CLIENT[Aplicaciones Cliente]
        API_GW[API Gateway]
    end
    
    subgraph "âš›ï¸ Quantum ML Service - Puerto 8007"
        FASTAPI[FastAPI Server]
        
        subgraph "Modelos CuÃ¡nticos"
            VQC[Variational Quantum Classifier<br/>ClasificaciÃ³n de Documentos]
            QAUTO[Quantum Autoencoder<br/>CompresiÃ³n de Embeddings]
            QANOM[Quantum Anomaly Detector<br/>DetecciÃ³n de Outliers]
        end
        
        subgraph "Backend CuÃ¡ntico"
            PENNYLANE[PennyLane Framework<br/>DiferenciaciÃ³n AutomÃ¡tica]
            QDEV[Quantum Device<br/>default.qubit<br/>4 qubits, 3 layers]
            QCIRCUIT[Circuitos CuÃ¡nticos<br/>StronglyEntanglingLayers]
        end
        
        subgraph "Explainability"
            SHAP_Q[SHAP TreeExplainer<br/>Quantum Circuits]
            METRICS_Q[MÃ©tricas CuÃ¡nticas<br/>Circuit Depth, Gates]
        end
    end
    
    subgraph "ğŸ”— Servicios Integrados"
        GPU_EMB[GPU Embedding Service<br/>Puerto 8001]
        ASTRA_DB[Astra VectorDB<br/>Puerto 8006]
        PROMETHEUS[Prometheus<br/>Puerto 9090]
    end
    
    CLIENT --> API_GW
    API_GW --> FASTAPI
    
    FASTAPI --> VQC
    FASTAPI --> QAUTO
    FASTAPI --> QANOM
    
    VQC --> PENNYLANE
    QAUTO --> PENNYLANE
    QANOM --> PENNYLANE
    
    PENNYLANE --> QDEV
    QDEV --> QCIRCUIT
    
    VQC --> SHAP_Q
    QAUTO --> SHAP_Q
    
    FASTAPI --> METRICS_Q
    
    FASTAPI -.->|Obtener Embeddings| GPU_EMB
    FASTAPI -.->|Almacenar Resultados| ASTRA_DB
    METRICS_Q -->|Scrape MÃ©tricas| PROMETHEUS
    
    style VQC fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style QAUTO fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style QANOM fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style PENNYLANE fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style QDEV fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style QCIRCUIT fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style SHAP_Q fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style FASTAPI fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
```

### Flujo de ClasificaciÃ³n CuÃ¡ntica

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'primaryColor':'#00d4ff','primaryTextColor':'#000','primaryBorderColor':'#0099cc','lineColor':'#00ff88','secondaryColor':'#ffaa00','tertiaryColor':'#ff00ff','noteBkgColor':'#ffaa00','noteTextColor':'#000','noteBorderColor':'#ff8800','actorBkg':'#00d4ff','actorBorder':'#0099cc','actorTextColor':'#000','actorLineColor':'#00ff88','signalColor':'#00ff88','signalTextColor':'#fff','labelBoxBkgColor':'#ff00ff','labelBoxBorderColor':'#cc00cc','labelTextColor':'#000','loopTextColor':'#000','activationBorderColor':'#0099cc','activationBkgColor':'#00d4ff','sequenceNumberColor':'#000'}}}%%
sequenceDiagram
    participant C as Cliente
    participant API as FastAPI
    participant VQC as Quantum Classifier
    participant PL as PennyLane
    participant QD as Quantum Device
    participant SHAP as SHAP Explainer
    
    C->>API: POST /qml/classify
    Note over C,API: {embedding: [0.1, 0.2, ...],<br/>explain: true}
    
    API->>VQC: classify(embedding)
    VQC->>VQC: preprocess_input()
    Note over VQC: Normalizar a [0, 2Ï€]<br/>para Angle Encoding
    
    VQC->>PL: quantum_neural_network()
    PL->>QD: Ejecutar circuito
    
    Note over QD: 1. AngleEmbedding<br/>2. StronglyEntanglingLayers<br/>3. Medir Pauli-Z
    
    QD-->>PL: quantum_output
    PL-->>VQC: expectation_values
    
    VQC->>VQC: softmax(quantum_output)
    Note over VQC: Convertir a probabilidades
    
    VQC->>SHAP: compute_shap_values()
    SHAP->>SHAP: Calcular contribuciones
    SHAP-->>VQC: shap_values
    
    VQC-->>API: classification_result
    Note over API: {predicted_class: 2,<br/>confidence: 0.85,<br/>quantum_output: [...],<br/>shap_values: [...]}
    
    API-->>C: JSON Response
```

### Ventajas del Quantum ML

| CaracterÃ­stica | DescripciÃ³n | Beneficio |
|---|---|---|
| **Ventaja CuÃ¡ntica** | Procesamiento paralelo cuÃ¡ntico | >1.2x vs modelos clÃ¡sicos en alta dimensiÃ³n |
| **GeneralizaciÃ³n** | Mejor con pocos datos | Reduce overfitting |
| **Expresividad** | Espacios de Hilbert exponenciales | Captura patrones complejos |
| **Explainability** | SHAP para circuitos cuÃ¡nticos | Transparencia total |

### Casos de Uso Quantum ML

1. **ClasificaciÃ³n de Documentos Complejos**
   - Documentos con mÃºltiples idiomas
   - Estructuras no lineales
   - Patrones ocultos en embeddings

2. **OptimizaciÃ³n de Embeddings**
   - ReducciÃ³n de dimensionalidad cuÃ¡ntica
   - CompresiÃ³n sin pÃ©rdida de informaciÃ³n
   - Autoencoders variacionales

3. **DetecciÃ³n de AnomalÃ­as**
   - Documentos fraudulentos
   - Patrones inusuales
   - Outliers en alta dimensiÃ³n

---

## ğŸ¤– Arquitectura AWS SageMaker - Predictive ML

### Diagrama de Componente

```mermaid
graph TB
    subgraph "ğŸŒ Client Layer"
        CLIENT[Aplicaciones Cliente]
        API_GW[API Gateway]
    end
    
    subgraph "ğŸ¤– SageMaker Predictor Service - Puerto 8008"
        FASTAPI[FastAPI Server]
        
        subgraph "Modelos ML"
            LGBM[LightGBM Classifier<br/>Gradient Boosting]
            XGB[XGBoost Classifier<br/>Extreme Gradient Boosting]
        end
        
        subgraph "Explainability"
            SHAP[SHAP TreeExplainer<br/>Feature Importance]
            CONTRIB[Feature Contributions<br/>Waterfall Plots]
        end
        
        subgraph "Model Management"
            LOADER[Model Loader<br/>Pickle/Joblib]
            CACHE[Model Cache<br/>In-Memory]
            DUMMY[Dummy Models<br/>Development]
        end
        
        subgraph "Monitoring"
            PROM_M[Prometheus Metrics<br/>Latency, Confidence]
            HEALTH[Health Checks]
        end
    end
    
    subgraph "â˜ï¸ AWS Services (Opcional)"
        SM_ENDPOINT[SageMaker Endpoint<br/>ProducciÃ³n]
        
        subgraph "Training Pipeline"
            S3_DATA[S3 Data Bucket<br/>Datasets]
            GLUE[AWS Glue<br/>Data Processing]
            SM_TRAIN[SageMaker Training<br/>ml.c5.xlarge]
            S3_MODEL[S3 Model Bucket<br/>Artifacts]
        end
        
        ECR[Amazon ECR<br/>Container Registry]
    end
    
    subgraph "ğŸ”— Servicios Integrados"
        ASTRA_DB[Astra VectorDB<br/>Almacenar Predicciones]
        PROMETHEUS[Prometheus<br/>Monitoring]
    end
    
    CLIENT --> API_GW
    API_GW --> FASTAPI
    
    FASTAPI --> LGBM
    FASTAPI --> XGB
    
    LGBM --> SHAP
    XGB --> SHAP
    SHAP --> CONTRIB
    
    LOADER --> LGBM
    LOADER --> XGB
    LOADER --> CACHE
    LOADER --> DUMMY
    
    FASTAPI --> PROM_M
    FASTAPI --> HEALTH
    
    FASTAPI -.->|Modo ProducciÃ³n| SM_ENDPOINT
    
    S3_DATA --> GLUE
    GLUE --> SM_TRAIN
    SM_TRAIN --> S3_MODEL
    S3_MODEL --> SM_ENDPOINT
    ECR --> SM_ENDPOINT
    
    FASTAPI -.->|Guardar Resultados| ASTRA_DB
    PROM_M -->|Scrape| PROMETHEUS
    
    style LGBM fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style XGB fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style SHAP fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style CONTRIB fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style SM_ENDPOINT fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style FASTAPI fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style DUMMY fill:#ff6600,stroke:#cc5200,stroke-width:3px,color:#000
```

### Flujo de PredicciÃ³n con Explainability

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'primaryColor':'#00d4ff','primaryTextColor':'#000','primaryBorderColor':'#0099cc','lineColor':'#00ff88','secondaryColor':'#ffaa00','tertiaryColor':'#ff00ff','noteBkgColor':'#ffaa00','noteTextColor':'#000','noteBorderColor':'#ff8800','actorBkg':'#00d4ff','actorBorder':'#0099cc','actorTextColor':'#000','actorLineColor':'#00ff88','signalColor':'#00ff88','signalTextColor':'#fff','labelBoxBkgColor':'#ff00ff','labelBoxBorderColor':'#cc00cc','labelTextColor':'#000','loopTextColor':'#000','activationBorderColor':'#0099cc','activationBkgColor':'#00d4ff','sequenceNumberColor':'#000','altBkgColor':'#ff6600'}}}%%
sequenceDiagram
    participant C as Cliente
    participant API as FastAPI
    participant M as ML Model
    participant SHAP as SHAP Explainer
    participant DB as Astra DB
    
    C->>API: POST /predict
    Note over C,API: {features: {<br/>  amount: 25000,<br/>  duration: 24,<br/>  age: 35<br/>}, explain: true}
    
    API->>M: Load Model
    Note over M: LightGBM o XGBoost
    
    API->>M: predict(features)
    M->>M: Feature Engineering
    Note over M: NormalizaciÃ³n<br/>Encoding categÃ³rico
    
    M->>M: Model Inference
    M-->>API: prediction + probabilities
    Note over API: prediction: 1<br/>probability: 0.85
    
    alt Explain = True
        API->>SHAP: compute_shap_values()
        Note over SHAP: TreeExplainer<br/>Calcular contribuciones
        
        SHAP->>SHAP: For each feature
        Note over SHAP: amount: +0.15<br/>duration: -0.05<br/>age: +0.08
        
        SHAP-->>API: shap_values + base_value
        
        API->>API: Format explanation
        Note over API: Feature names<br/>Feature values<br/>SHAP values<br/>Base value
    end
    
    API->>DB: Store prediction
    Note over DB: Guardar para<br/>anÃ¡lisis posterior
    
    API-->>C: JSON Response
    Note over C,API: {prediction: 1,<br/>probability: 0.85,<br/>risk_score: 85.0,<br/>explanation: {...}}
```

### Capacidades del SageMaker Predictor

| CaracterÃ­stica | DescripciÃ³n | Beneficio |
|---|---|---|
| **Dual Model Support** | LightGBM + XGBoost | ComparaciÃ³n de rendimiento |
| **SHAP Explainability** | ContribuciÃ³n de cada feature | Transparencia total |
| **Batch Processing** | Predicciones masivas | Alta eficiencia |
| **AWS Integration** | SageMaker opcional | Escalabilidad cloud |
| **Local Development** | Modelos dummy | Sin costos AWS |

### Casos de Uso Predictive ML

1. **EvaluaciÃ³n de CrÃ©dito**
   - Scoring de solicitudes
   - AnÃ¡lisis de riesgo
   - ExplicaciÃ³n de decisiones

2. **AnÃ¡lisis de Riesgo Financiero**
   - PredicciÃ³n de default
   - ClasificaciÃ³n de documentos
   - DetecciÃ³n de fraude

3. **AprobaciÃ³n de PrÃ©stamos**
   - DecisiÃ³n automÃ¡tica
   - ExplicaciÃ³n regulatoria
   - Cumplimiento normativo

### InterpretaciÃ³n SHAP

**Ejemplo de ExplicaciÃ³n:**

```
Base Value: 0.50 (50% probabilidad base)

Feature Contributions:
+ Amount (25000â‚¬):        +0.15  â†’ Aumenta riesgo
- Duration (24 meses):    -0.05  â†’ Reduce riesgo
+ Age (35 aÃ±os):          +0.08  â†’ Aumenta confianza
+ Employment (60 meses):  +0.12  â†’ Aumenta confianza
- Dependents (2):         -0.02  â†’ Reduce ligeramente

Final Prediction: 0.85 (85% probabilidad)
Risk Score: 85/100
```

**InterpretaciÃ³n:**
- Valores SHAP **positivos**: Aumentan la probabilidad de la clase positiva
- Valores SHAP **negativos**: Disminuyen la probabilidad
- **Base value**: PredicciÃ³n promedio del modelo
- **Suma de contribuciones**: Lleva del base value a la predicciÃ³n final

---

## ğŸ¯ Arquitectura de Scoring HÃ­brido - Sistema Completo

### VisiÃ³n General del Sistema de Scoring

El sistema implementa un **scoring hÃ­brido inteligente** que combina datos estructurados (CRM/ERP) con informaciÃ³n no estructurada (documentos, emails, contratos) utilizando mÃºltiples modelos de Machine Learning y Quantum Computing.

### Diagrama de Arquitectura Completa

```mermaid
graph TB
    subgraph "ğŸ‘¤ Cliente"
        CLIENT[Cliente/OperaciÃ³n]
    end
    
    subgraph "ğŸ“Š Datos de Entrada"
        STRUCT[Datos Estructurados<br/>Edad, Ingresos, Historial]
        DOCS[Documentos No Estructurados<br/>PDFs, Contratos, Emails]
    end
    
    subgraph "ğŸ” Procesamiento de Documentos"
        DOC_EXT[Document Feature Extractor<br/>Puerto 8009]
        FEATURES[Features ExtraÃ­das<br/>â€¢ Sentiment<br/>â€¢ Entidades<br/>â€¢ Riesgo<br/>â€¢ Calidad]
    end
    
    subgraph "ğŸ¤– Modelos de Machine Learning"
        SAGE[SageMaker Predictor<br/>Puerto 8008<br/>LightGBM + XGBoost]
        QML[Quantum ML PennyLane<br/>Puerto 8007<br/>VQC + Anomaly]
        SHAP_S[SHAP Explainer<br/>TreeExplainer]
        SHAP_Q[SHAP Explainer<br/>Quantum Features]
    end
    
    subgraph "ğŸ¯ OrquestaciÃ³n y Ensemble"
        ORCH[Scoring Orchestrator<br/>Puerto 8010]
        ENSEMBLE[Ensemble Scoring<br/>50% ML + 30% Quantum + 20% Docs]
        DECISION{DecisiÃ³n Final}
    end
    
    subgraph "ğŸ“ˆ Resultado"
        SCORE[Score Final: 0-100]
        EXPLAIN[ExplicaciÃ³n Completa<br/>â€¢ Factores principales<br/>â€¢ Contribuciones<br/>â€¢ Confianza]
        ACTION[AcciÃ³n<br/>APPROVED / REVIEW / REJECTED]
    end
    
    CLIENT --> STRUCT
    CLIENT --> DOCS
    
    DOCS --> DOC_EXT
    DOC_EXT --> FEATURES
    
    STRUCT --> ORCH
    FEATURES --> ORCH
    
    ORCH --> SAGE
    ORCH --> QML
    
    SAGE --> SHAP_S
    QML --> SHAP_Q
    
    SHAP_S --> ENSEMBLE
    SHAP_Q --> ENSEMBLE
    FEATURES --> ENSEMBLE
    
    ENSEMBLE --> DECISION
    DECISION --> SCORE
    DECISION --> EXPLAIN
    DECISION --> ACTION
    
    style CLIENT fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style STRUCT fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style DOCS fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style DOC_EXT fill:#ff6600,stroke:#cc5200,stroke-width:3px,color:#000
    style FEATURES fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style SAGE fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style QML fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style SHAP_S fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style SHAP_Q fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style ORCH fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style ENSEMBLE fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style DECISION fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style SCORE fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style EXPLAIN fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style ACTION fill:#ff6600,stroke:#cc5200,stroke-width:3px,color:#000
```

### Flujo de Scoring Completo

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'primaryColor':'#00d4ff','primaryTextColor':'#000','primaryBorderColor':'#0099cc','lineColor':'#00ff88','secondaryColor':'#ffaa00','tertiaryColor':'#ff00ff','noteBkgColor':'#ffaa00','noteTextColor':'#000','noteBorderColor':'#ff8800','actorBkg':'#00d4ff','actorBorder':'#0099cc','actorTextColor':'#000','actorLineColor':'#00ff88','signalColor':'#00ff88','signalTextColor':'#fff','labelBoxBkgColor':'#ff00ff','labelBoxBorderColor':'#cc00cc','labelTextColor':'#000','loopTextColor':'#000','activationBorderColor':'#0099cc','activationBkgColor':'#00d4ff','sequenceNumberColor':'#000','altBkgColor':'#ff6600'}}}%%
sequenceDiagram
    participant C as Cliente
    participant O as Orchestrator
    participant D as Doc Extractor
    participant S as SageMaker
    participant Q as Quantum ML
    participant E as Ensemble
    
    C->>O: Request Scoring
    Note over C,O: Datos estructurados<br/>+ Documentos
    
    par Procesamiento Paralelo
        O->>D: Extraer Features
        Note over D: Sentiment, Entidades<br/>Riesgo, Calidad
        D-->>O: Document Features
    and
        O->>S: Predict (Structured + Doc Features)
        Note over S: LightGBM/XGBoost<br/>+ SHAP
        S-->>O: Score ML + ExplicaciÃ³n
    and
        O->>Q: Classify (Embedding)
        Note over Q: Quantum VQC<br/>+ SHAP
        Q-->>O: Score Quantum + Confianza
    end
    
    O->>E: Compute Ensemble
    Note over E: 50% ML ClÃ¡sico<br/>30% Quantum<br/>20% Documentos
    
    E->>E: Calculate Final Score
    E->>E: Determine Decision
    E->>E: Generate Explanation
    
    E-->>O: Final Result
    O-->>C: Score + DecisiÃ³n + ExplicaciÃ³n
    Note over C,O: Score: 76.5<br/>Decision: APPROVED<br/>Confidence: 85%
```

### Componentes del Sistema

| Componente | Puerto | FunciÃ³n | TecnologÃ­a |
|---|---|---|---|
| **Document Feature Extractor** | 8009 | Extrae features de documentos no estructurados | FastAPI + NLP + Regex |
| **SageMaker Predictor** | 8008 | Scoring ML clÃ¡sico con explainability | LightGBM + XGBoost + SHAP |
| **Quantum ML PennyLane** | 8007 | ClasificaciÃ³n cuÃ¡ntica y detecciÃ³n de anomalÃ­as | PennyLane + VQC + SHAP |
| **Scoring Orchestrator** | 8010 | Orquesta modelos y genera score final | FastAPI + Async HTTP + Ensemble |
| **Astra Vector DB** | 8006 | Almacena embeddings y resultados | DataStax Astra + Vector Search |
| **Prometheus** | 9090 | Monitoreo y mÃ©tricas | Prometheus |
| **Grafana** | 3001 | VisualizaciÃ³n de mÃ©tricas | Grafana |

### Algoritmo de Ensemble

El score final se calcula mediante un **weighted ensemble** que combina las predicciones de mÃºltiples modelos:

```python
final_score = (
    0.50 * sagemaker_score +      # 50% - ML ClÃ¡sico (LightGBM/XGBoost)
    0.30 * quantum_score +         # 30% - Quantum ML (VQC)
    0.20 * document_quality_score  # 20% - Calidad Documental
)
```

### Decisiones AutomÃ¡ticas

| Score Range | DecisiÃ³n | AcciÃ³n | Confianza |
|---|---|---|---|
| **75-100** | âœ… `APPROVED` | AprobaciÃ³n automÃ¡tica | Alta (>85%) |
| **60-74** | âš ï¸ `APPROVED_WITH_CONDITIONS` | AprobaciÃ³n condicional | Media (75%) |
| **40-59** | ğŸ” `REVIEW_REQUIRED` | RevisiÃ³n manual necesaria | Media (60%) |
| **0-39** | âŒ `REJECTED` | Rechazo automÃ¡tico | Alta (>85%) |

### Features ExtraÃ­das de Documentos

#### AnÃ¡lisis de Sentimiento
- Score general (-1 a 1)
- Ratio de sentimiento positivo

#### ExtracciÃ³n de Entidades
- Montos monetarios (â‚¬, $, USD)
- Fechas mencionadas
- Identificadores (NIF, CIF, DNI)

#### Indicadores de Riesgo
- Palabras clave de riesgo
- Menciones de retrasos de pago
- Problemas legales

#### Calidad Documental
- Completitud (0-1)
- Calidad del texto (0-1)
- Presencia de datos estructurados

### Explicabilidad Completa

El sistema proporciona explicaciones detalladas para cada decisiÃ³n:

#### Factores Principales
```
âœ… Alta probabilidad de aprobaciÃ³n ML clÃ¡sico (82%)
âœ… Alta confianza en modelo cuÃ¡ntico (78%)
âœ… Sentimiento positivo en documentos (0.65)
âœ… DocumentaciÃ³n completa (85%)
âš ï¸ 1 indicador de riesgo detectado
```

#### Contribuciones por Fuente
- **Datos Estructurados**: 50% (edad, ingresos, historial)
- **Datos No Estructurados**: 20% (documentos, sentiment)
- **Quantum ML**: 30% (patrones complejos, anomalÃ­as)

#### Top Features
**Positivas:**
- `income`: +0.15 (Ingresos altos)
- `credit_history`: +0.12 (Buen historial)
- `doc_sentiment`: +0.08 (Sentimiento positivo)

**Negativas:**
- `risk_indicators`: -0.08 (Indicadores de riesgo)
- `payment_delays`: -0.05 (Menciones de retrasos)

### Ventajas del Sistema HÃ­brido

| Ventaja | DescripciÃ³n | Beneficio |
|---|---|---|
| **ğŸ¯ Mayor PrecisiÃ³n** | Combina mÃºltiples fuentes de datos | +15% accuracy vs modelos individuales |
| **ğŸ” VisiÃ³n Completa** | Analiza datos estructurados + no estructurados | Decisiones mÃ¡s informadas |
| **âš›ï¸ Ventaja CuÃ¡ntica** | Detecta patrones no lineales complejos | Mejor en casos edge |
| **ğŸ“Š Explainability** | SHAP values + contribuciones por fuente | Compliance y transparencia |
| **ğŸ›¡ï¸ Robustez** | Si un modelo falla, otros compensan | Alta disponibilidad |
| **âš¡ Escalable** | Procesamiento paralelo asÃ­ncrono | Baja latencia (<200ms) |

### Casos de Uso

#### 1. Scoring de CrÃ©dito Completo
- **Input**: Datos financieros + contratos + historial de comunicaciones
- **Output**: Score 0-100 + decisiÃ³n automÃ¡tica + explicaciÃ³n
- **Beneficio**: Decisiones mÃ¡s precisas considerando contexto completo

#### 2. EvaluaciÃ³n de Riesgo Empresarial
- **Input**: Estados financieros + documentos legales + noticias
- **Output**: Nivel de riesgo + factores clave + recomendaciones
- **Beneficio**: DetecciÃ³n temprana de problemas

#### 3. Due Diligence Automatizada
- **Input**: DocumentaciÃ³n corporativa completa
- **Output**: Score de completitud + gaps + calidad documental
- **Beneficio**: Acelera procesos de M&A y auditorÃ­as

#### 4. AprobaciÃ³n Inteligente de Operaciones
- **Input**: Solicitud + documentaciÃ³n + historial cliente
- **Output**: AprobaciÃ³n/rechazo automÃ¡tico con justificaciÃ³n
- **Beneficio**: Reduce tiempo de decisiÃ³n de dÃ­as a segundos

### MÃ©tricas de Rendimiento

| MÃ©trica | Valor | DescripciÃ³n |
|---|---|---|
| **Latencia P50** | <150ms | 50% de requests |
| **Latencia P95** | <300ms | 95% de requests |
| **Latencia P99** | <500ms | 99% de requests |
| **Throughput** | 100 req/s | Requests por segundo |
| **Accuracy** | 92% | PrecisiÃ³n en validaciÃ³n |
| **Recall** | 89% | Cobertura de casos positivos |
| **F1-Score** | 90.5% | Balance precision/recall |
| **AUC-ROC** | 0.94 | Ãrea bajo la curva |

### Monitoreo y Observabilidad

Todas las mÃ©tricas estÃ¡n disponibles en **Prometheus** (puerto 9090) y visualizables en **Grafana** (puerto 3001):

- `scoring_requests_total`: Total de requests de scoring
- `scoring_duration_seconds`: Tiempo de procesamiento
- `model_calls_total{model, status}`: Llamadas a cada modelo
- `ensemble_scores`: DistribuciÃ³n de scores finales
- `extraction_requests_total`: Features extraÃ­das de documentos
- `quantum_predictions_total`: Predicciones cuÃ¡nticas
- `sagemaker_predictions_total`: Predicciones ML clÃ¡sico

---

## ğŸ’³ Modelo de Tarjetas de CrÃ©dito - Credit Risk ML

### Arquitectura del Modelo Entrenado

```mermaid
graph TB
    subgraph "ğŸ“Š Datos de Entrada"
        CSV[Train Dataset<br/>45,530 registros<br/>19 columnas]
    end
    
    subgraph "ğŸ”§ Preprocesamiento"
        CLEAN[Limpieza de Datos<br/>â€¢ Eliminar ID/Name<br/>â€¢ Imputar faltantes<br/>â€¢ Codificar categÃ³ricas]
        FE[Feature Engineering<br/>â€¢ credit_utilization_ratio<br/>â€¢ debt_to_income_ratio<br/>â€¢ credit_used_amount<br/>â€¢ income_per_family_member<br/>â€¢ years_employed<br/>â€¢ high_risk_indicator]
    end
    
    subgraph "ğŸ¯ Modelos"
        GB[Gradient Boosting<br/>200 estimators<br/>max_depth=5]
        CAL[CalibraciÃ³n<br/>Sigmoid Method<br/>CV=3]
        IF[Isolation Forest<br/>Detector de Fraude<br/>contamination=5%]
    end
    
    subgraph "ğŸ“ˆ Resultados"
        METRICS[MÃ©tricas Excelentes<br/>AUC-ROC: 0.9955<br/>Accuracy: 98.01%<br/>F1-Score: 86.50%]
        MODELS[Modelos Guardados<br/>Version: 20251028_190524<br/>4 archivos .pkl]
    end
    
    CSV --> CLEAN
    CLEAN --> FE
    FE --> GB
    GB --> CAL
    FE --> IF
    CAL --> METRICS
    IF --> METRICS
    METRICS --> MODELS
    
    style CSV fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style CLEAN fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style FE fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
    style GB fill:#ff00ff,stroke:#cc00cc,stroke-width:3px,color:#000
    style CAL fill:#ff6600,stroke:#cc5200,stroke-width:3px,color:#000
    style IF fill:#00d4ff,stroke:#0099cc,stroke-width:3px,color:#000
    style METRICS fill:#00ff88,stroke:#00cc66,stroke-width:3px,color:#000
    style MODELS fill:#ffaa00,stroke:#ff8800,stroke-width:3px,color:#000
```

### Pipeline de Entrenamiento

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'primaryColor':'#00d4ff','primaryTextColor':'#000','primaryBorderColor':'#0099cc','lineColor':'#00ff88','secondaryColor':'#ffaa00','tertiaryColor':'#ff00ff','noteBkgColor':'#ffaa00','noteTextColor':'#000','noteBorderColor':'#ff8800','actorBkg':'#00d4ff','actorBorder':'#0099cc','actorTextColor':'#000','actorLineColor':'#00ff88','signalColor':'#00ff88','signalTextColor':'#fff','labelBoxBkgColor':'#ff00ff','labelBoxBorderColor':'#cc00cc','labelTextColor':'#000','loopTextColor':'#000','activationBorderColor':'#0099cc','activationBkgColor':'#00d4ff','sequenceNumberColor':'#000','altBkgColor':'#ff6600'}}}%%
sequenceDiagram
    participant D as Dataset
    participant P as Preprocessor
    participant F as Feature Engineer
    participant T as Trainer
    participant E as Evaluator
    participant S as Storage
    
    D->>P: Load train.csv (45,530 rows)
    Note over D,P: Default rate: 11.63%
    
    P->>P: Clean Data
    Note over P: Remove ID/Name<br/>Impute missing<br/>Encode categorical
    
    P->>F: Cleaned Data
    F->>F: Create 6 Derived Features
    Note over F: Ratios, indicators,<br/>transformations
    
    F->>T: 23 Features Ready
    T->>T: Train Gradient Boosting
    Note over T: 200 iterations<br/>Learning rate: 0.1<br/>Max depth: 5
    
    T->>T: Calibrate Probabilities
    Note over T: Sigmoid calibration<br/>CV=3
    
    T->>T: Train Fraud Detector
    Note over T: Isolation Forest<br/>5% contamination
    
    T->>E: Models Ready
    E->>E: Evaluate on Test Set
    Note over E: 9,106 samples<br/>AUC-ROC: 0.9955<br/>Accuracy: 98.01%
    
    E->>S: Save Models
    Note over S: 4 files saved<br/>Version: 20251028_190524
    
    S-->>D: Training Complete âœ…
```

### Resultados del Entrenamiento

#### ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor | Objetivo | Estado |
|---|---|---|---|
| **AUC-ROC** | **0.9955** | >0.80 | âœ… Excelente |
| **AUC-PR** | **0.9587** | >0.70 | âœ… Excelente |
| **Accuracy** | **98.01%** | >85% | âœ… Excelente |
| **Precision** | **96.35%** | >75% | âœ… Excelente |
| **Recall** | **78.48%** | >70% | âœ… Bueno |
| **F1-Score** | **86.50%** | >72% | âœ… Excelente |
| **Brier Score** | **0.0132** | <0.15 | âœ… Muy bien calibrado |
| **Log Loss** | **0.0397** | <0.50 | âœ… Muy bajo |

#### ğŸ“ˆ Matriz de ConfusiÃ³n

```
                    PredicciÃ³n
                 No Default  |  Default
    Real         
    No Default      8,345    |    22      (99.7% correctos)
    Default           159    |   580      (78.5% correctos)
    
    Total: 9,106 muestras
```

**InterpretaciÃ³n:**
- âœ… **True Negatives**: 8,345 - Excelente identificaciÃ³n de casos sin default
- âœ… **True Positives**: 580 - Buena detecciÃ³n de defaults reales
- âš ï¸ **False Positives**: 22 - Muy pocos falsos positivos (0.26%)
- âš ï¸ **False Negatives**: 159 - Algunos defaults no detectados (21.5%)

#### ğŸ” Top 15 Features MÃ¡s Importantes

| Rank | Feature | Importancia | DescripciÃ³n |
|---|---|---|---|
| 1 | `prev_defaults` | 0.6598 | â­ Defaults previos (factor crÃ­tico) |
| 2 | `default_in_last_6months` | 0.1018 | Default reciente |
| 3 | `credit_score` | 0.0748 | Score crediticio |
| 4 | `credit_utilization_ratio` | 0.0290 | Ratio de uso de crÃ©dito |
| 5 | `credit_used_amount` | 0.0134 | Monto usado absoluto |
| 6 | `debt_to_income_ratio` | 0.0114 | Ratio deuda/ingresos |
| 7 | `credit_limit` | 0.0102 | LÃ­mite de crÃ©dito |
| 8 | `yearly_debt_payments` | 0.0097 | Pagos anuales de deuda |
| 9 | `income_per_family_member` | 0.0080 | Ingreso per cÃ¡pita |
| 10 | `years_employed` | 0.0078 | AÃ±os de empleo |
| 11 | `net_yearly_income` | 0.0074 | Ingresos anuales |
| 12 | `age` | 0.0065 | Edad del cliente |
| 13 | `no_of_days_employed` | 0.0059 | DÃ­as empleado |
| 14 | `occupation_type` | 0.0048 | Tipo de ocupaciÃ³n |
| 15 | `gender` | 0.0041 | GÃ©nero |

#### ğŸ” Detector de Fraude

- **AnomalÃ­as detectadas**: 475 casos (5.22%)
- **MÃ©todo**: Isolation Forest
- **Contamination**: 5%
- **Estado**: âœ… Funcionando correctamente

#### â±ï¸ Performance de Entrenamiento

| MÃ©trica | Valor |
|---|---|
| **Tiempo total** | 77.96 segundos |
| **Registros procesados** | 45,530 |
| **Train samples** | 36,424 (80%) |
| **Test samples** | 9,106 (20%) |
| **Features finales** | 23 |
| **Iteraciones GB** | 200 |

#### ğŸ’¾ Modelos Generados

```
models/
â”œâ”€â”€ credit_card_model_v20251028_190524.pkl      # Modelo principal (GB + CalibraciÃ³n)
â”œâ”€â”€ fraud_detector_v20251028_190524.pkl         # Detector de fraude (IF)
â”œâ”€â”€ label_encoders_v20251028_190524.pkl         # Encoders para categÃ³ricas
â””â”€â”€ metadata_v20251028_190524.pkl               # Metadata + mÃ©tricas
```

**Version**: `20251028_190524`

### CaracterÃ­sticas del Modelo

#### Features Originales (17)
- DemogrÃ¡ficas: `age`, `gender`, `no_of_children`
- Financieras: `net_yearly_income`, `yearly_debt_payments`, `credit_limit`, `credit_limit_used(%)`
- Crediticias: `credit_score`, `prev_defaults`, `default_in_last_6months`
- Empleo: `no_of_days_employed`, `occupation_type`
- Propiedades: `owns_car`, `owns_house`
- Familiares: `total_family_members`, `migrant_worker`

#### Features Derivadas (6)
- `credit_utilization_ratio`: NormalizaciÃ³n del uso de crÃ©dito
- `debt_to_income_ratio`: Ratio de endeudamiento
- `credit_used_amount`: Monto absoluto usado
- `income_per_family_member`: Ingreso per cÃ¡pita familiar
- `years_employed`: ConversiÃ³n de dÃ­as a aÃ±os
- `high_risk_indicator`: Indicador combinado de alto riesgo

### Uso del Modelo

#### Cargar Modelo Entrenado

```python
import joblib

# Cargar artefactos
model = joblib.load("models/credit_card_model_v20251028_190524.pkl")
fraud_detector = joblib.load("models/fraud_detector_v20251028_190524.pkl")
encoders = joblib.load("models/label_encoders_v20251028_190524.pkl")
metadata = joblib.load("models/metadata_v20251028_190524.pkl")

print(f"Modelo: {metadata['version']}")
print(f"AUC-ROC: {metadata['metrics']['auc_roc']:.4f}")
```

#### Hacer PredicciÃ³n

```python
# Preparar datos de entrada (aplicar mismo preprocesamiento)
customer_data = {
    'age': 35,
    'gender': 'M',
    'owns_car': 'Y',
    'owns_house': 'Y',
    'no_of_children': 2,
    'net_yearly_income': 150000,
    'no_of_days_employed': 2000,
    'occupation_type': 'Core staff',
    'total_family_members': 4,
    'migrant_worker': 0,
    'yearly_debt_payments': 25000,
    'credit_limit': 50000,
    'credit_limit_used(%)': 65,
    'credit_score': 720,
    'prev_defaults': 0,
    'default_in_last_6months': 0
}

# Preprocesar y predecir
X = preprocess(customer_data)  # Aplicar mismo pipeline
probability = model.predict_proba(X)[0][1]
is_fraud = fraud_detector.predict(X)[0] == -1

print(f"Probabilidad de default: {probability:.2%}")
print(f"Fraude detectado: {'SÃ­' if is_fraud else 'No'}")
```

### Ventajas del Modelo

| Ventaja | DescripciÃ³n | Beneficio |
|---|---|---|
| **ğŸ¯ Alta PrecisiÃ³n** | AUC-ROC de 0.9955 | Decisiones muy confiables |
| **âš¡ RÃ¡pido** | <100ms por predicciÃ³n | Scoring en tiempo real |
| **ğŸ“Š Bien Calibrado** | Brier Score: 0.0132 | Probabilidades confiables |
| **ğŸ” DetecciÃ³n de Fraude** | Isolation Forest integrado | Seguridad adicional |
| **ğŸ“ˆ Explicable** | Feature importance + SHAP | Cumplimiento regulatorio |
| **ğŸ”„ Reproducible** | Pipeline automatizado | FÃ¡cil reentrenamiento |

### Casos de Uso

1. **AprobaciÃ³n AutomÃ¡tica de Tarjetas**
   - Input: Datos del solicitante
   - Output: Probabilidad de default + decisiÃ³n
   - Beneficio: ReducciÃ³n de 90% en tiempo de decisiÃ³n

2. **Scoring de Cartera Existente**
   - Input: Base de clientes actuales
   - Output: Re-scoring periÃ³dico
   - Beneficio: GestiÃ³n proactiva de riesgo

3. **DetecciÃ³n de Fraude en Solicitudes**
   - Input: Datos de nueva solicitud
   - Output: Anomaly score + patrones sospechosos
   - Beneficio: PrevenciÃ³n de pÃ©rdidas

4. **OptimizaciÃ³n de LÃ­mites de CrÃ©dito**
   - Input: Historial + comportamiento
   - Output: LÃ­mite Ã³ptimo sugerido
   - Beneficio: Maximizar ingresos minimizando riesgo

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¤– Inteligencia Artificial

- **OCR Avanzado**: Tesseract + PyTesseract para documentos escaneados
- **NER (Named Entity Recognition)**: ExtracciÃ³n de personas, organizaciones, DNI, IBAN, fechas
- **ClasificaciÃ³n AutomÃ¡tica**: Modelo BETO fine-tuned para 10+ categorÃ­as documentales
- **Embeddings SemÃ¡nticos**: Sentence-BERT para representaciÃ³n vectorial
- **RAG (Retrieval Augmented Generation)**: Asistente conversacional con citaciÃ³n obligatoria

### ğŸ” BÃºsqueda y RecuperaciÃ³n

- **BÃºsqueda HÃ­brida**: Combina BM25 (lÃ©xica) + vectores (semÃ¡ntica) con re-ranking
- **Filtros Avanzados**: Por tipo, fecha, autor, categorÃ­a, riesgo, compliance
- **BÃºsqueda Facetada**: Agregaciones y estadÃ­sticas en tiempo real
- **BÃºsqueda Conversacional**: Interfaz de chat con contexto histÃ³rico

### âš–ï¸ Cumplimiento Normativo

- **EU AI Act 2024**: ClasificaciÃ³n de riesgo, documentaciÃ³n obligatoria, auditorÃ­a
- **GDPR/LOPDGDD**: AnonimizaciÃ³n, derecho al olvido, consentimiento
- **NIS2 Directive**: Ciberseguridad, gestiÃ³n de incidentes
- **ISO 27001/27701/42001**: GestiÃ³n de seguridad y privacidad
- **Motor de Reglas**: ValidaciÃ³n automÃ¡tica de compliance con evidencias

### ğŸ“Š AnÃ¡lisis y Reporting

- **Scoring de Riesgo**: AnÃ¡lisis multidimensional (legal, financiero, operacional)
- **Explicabilidad**: Cada decisiÃ³n con evidencias y razonamiento
- **Dashboards Interactivos**: MÃ©tricas operativas y de negocio
- **Alertas AutomÃ¡ticas**: Notificaciones de vencimientos, anomalÃ­as, incumplimientos

### ğŸ” Seguridad Enterprise

- **AutenticaciÃ³n**: SSO, LDAP/AD, MFA
- **AutorizaciÃ³n**: RBAC granular por documento y operaciÃ³n
- **Cifrado**: TLS 1.3 en trÃ¡nsito, AES-256 en reposo
- **AuditorÃ­a**: Logs inmutables de todas las operaciones
- **AnonimizaciÃ³n**: PII detection y enmascaramiento automÃ¡tico

---

## ğŸ¯ Funcionalidades Clave

### ğŸ“„ GestiÃ³n Documental

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **IngestiÃ³n Multi-canal** | Upload web, API REST, conectores (SharePoint, SAP DMS), carpetas vigiladas |
| **Procesamiento AutomÃ¡tico** | OCR, conversiÃ³n de formatos, normalizaciÃ³n, extracciÃ³n de metadatos |
| **Versionado** | Control de versiones con diff visual y rollback |
| **DeduplicaciÃ³n** | DetecciÃ³n automÃ¡tica de duplicados por hash SHA-256 |
| **ComparaciÃ³n** | Diff side-by-side de documentos con highlighting |
| **Anotaciones** | Sistema de comentarios y marcado colaborativo |

### ğŸ” BÃºsqueda Inteligente

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **BÃºsqueda Full-Text** | IndexaciÃ³n completa con OpenSearch (BM25) |
| **BÃºsqueda SemÃ¡ntica** | Vectores con Qdrant para bÃºsqueda por significado |
| **BÃºsqueda HÃ­brida** | FusiÃ³n de resultados lÃ©xicos y semÃ¡nticos con re-ranking |
| **Filtros DinÃ¡micos** | Por tipo, fecha, categorÃ­a, autor, riesgo, compliance |
| **Sugerencias** | Autocompletado y correcciÃ³n ortogrÃ¡fica |
| **Historial** | BÃºsquedas recientes y guardadas |

### ğŸ¤– Asistente IA (RAG)

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **Chat Conversacional** | Interfaz de chat con contexto histÃ³rico |
| **CitaciÃ³n Obligatoria** | Cada respuesta con fuentes y extractos relevantes |
| **Multi-documento** | Respuestas que sintetizan informaciÃ³n de mÃºltiples docs |
| **Explicabilidad** | Razonamiento paso a paso de las respuestas |
| **Observabilidad** | Monitoreo de prompts, latencia, tokens con Arize Phoenix |

### ğŸ“Š AnÃ¡lisis de Riesgo

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **Scoring Multidimensional** | Legal, financiero, operacional, reputacional |
| **Explicabilidad Total** | Evidencias y factores que contribuyen al score |
| **Alertas AutomÃ¡ticas** | Notificaciones de documentos de alto riesgo |
| **Tendencias** | EvoluciÃ³n del riesgo en el tiempo |
| **Reportes** | Informes ejecutivos y detallados |

### âš–ï¸ Compliance

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **Motor de Reglas** | ValidaciÃ³n automÃ¡tica de requisitos normativos |
| **AuditorÃ­a Completa** | Logs inmutables de todas las validaciones |
| **Evidencias** | Captura automÃ¡tica de pruebas de cumplimiento |
| **Alertas de Vencimiento** | Notificaciones de documentos prÃ³ximos a expirar |
| **Reportes Regulatorios** | GeneraciÃ³n automÃ¡tica de informes para autoridades |

### ğŸ§¬ Datos SintÃ©ticos

| Funcionalidad | DescripciÃ³n |
|---------------|-------------|
| **GeneraciÃ³n AutomÃ¡tica** | CreaciÃ³n de documentos sintÃ©ticos para testing |
| **Templates Configurables** | Distribuciones predefinidas (default, financial, contracts) |
| **Auto-upload** | Carga automÃ¡tica de documentos generados |
| **Historial** | Seguimiento de generaciones con mÃ©tricas |

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Backend

| Componente | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|-----------|---------|-----------|
| **Framework** | FastAPI | 0.104+ | API REST de alto rendimiento |
| **ORM** | SQLAlchemy | 2.0+ | AbstracciÃ³n de base de datos |
| **Task Queue** | Celery | 5.3+ | Procesamiento asÃ­ncrono |
| **Auth** | JWT + OAuth2 | - | AutenticaciÃ³n y autorizaciÃ³n |
| **ValidaciÃ³n** | Pydantic | 2.0+ | ValidaciÃ³n de datos |

### Frontend

| Componente | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|-----------|---------|-----------|
| **Framework** | React | 18+ | UI interactiva |
| **Lenguaje** | TypeScript | 5.0+ | Type safety |
| **Build Tool** | Vite | 4.0+ | Build rÃ¡pido y HMR |
| **UI Library** | Material-UI | 5.0+ | Componentes profesionales |
| **State Management** | React Query | 4.0+ | GestiÃ³n de estado servidor |
| **Routing** | React Router | 6.0+ | NavegaciÃ³n SPA |

### Datos y Almacenamiento

| Componente | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|-----------|---------|-----------|
| **Base de Datos** | PostgreSQL | 15+ | Datos relacionales + pgvector |
| **Full-Text Search** | OpenSearch | 2.11+ | BÃºsqueda lÃ©xica (BM25) |
| **Vector Database** | Qdrant | 1.7+ | BÃºsqueda semÃ¡ntica |
| **Cache** | Redis | 7.0+ | Cache + cola de tareas |
| **Object Storage** | MinIO | Latest | Almacenamiento S3-compatible |

### Machine Learning e IA

| Componente | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|-----------|---------|-----------|
| **LLM** | OpenAI GPT-4 | - | RAG y generaciÃ³n de texto |
| **Embeddings** | Sentence-BERT | - | VectorizaciÃ³n semÃ¡ntica |
| **NER** | SpaCy | 3.7+ | ExtracciÃ³n de entidades |
| **OCR** | Tesseract | 5.0+ | Reconocimiento de texto |
| **ML Framework** | PyTorch | 2.0+ | Modelos personalizados |
| **Observability** | Arize Phoenix | Latest | Monitoreo de LLMs |

### DevOps e Infraestructura

| Componente | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|-----------|---------|-----------|
| **ContainerizaciÃ³n** | Docker | 24+ | Empaquetado de servicios |
| **OrquestaciÃ³n** | Docker Compose | 2.0+ | OrquestaciÃ³n local |
| **CI/CD** | GitHub Actions | - | AutomatizaciÃ³n de pipelines |
| **Reverse Proxy** | NGINX | 1.25+ | Load balancing y SSL |
| **Monitoring** | Prometheus + Grafana | - | MÃ©tricas y alertas |

---

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- **Docker** 24.0+ y **Docker Compose** 2.0+
- **Git** para clonar el repositorio
- **8GB RAM** mÃ­nimo (16GB recomendado)
- **20GB** de espacio en disco
- **GPU NVIDIA** (opcional, para aceleraciÃ³n)

### InstalaciÃ³n EstÃ¡ndar

#### 1ï¸âƒ£ Clonar el Repositorio

```powershell
git clone https://github.com/rjamoriz/Sistema-Corporativo-Documental-con-Capacidades-de-IA.git
cd Sistema-Corporativo-Documental-con-Capacidades-de-IA
```

#### 2ï¸âƒ£ Configurar Variables de Entorno

```powershell
# Copiar el archivo de ejemplo
copy .env.example .env

# Editar .env con tus credenciales
notepad .env
```

**Variables crÃ­ticas a configurar:**

```env
# OpenAI API (requerido para RAG)
OPENAI_API_KEY=sk-...

# Base de datos
POSTGRES_PASSWORD=tu_password_seguro

# MinIO (S3)
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=tu_password_seguro

# JWT Secret
JWT_SECRET_KEY=genera_un_secret_aleatorio_seguro
```

#### 3ï¸âƒ£ Levantar los Servicios

```powershell
# Modo estÃ¡ndar (CPU)
docker-compose up -d

# Modo GPU (si tienes NVIDIA GPU)
docker-compose -f docker-compose.gpu.yml up -d
```

#### 4ï¸âƒ£ Verificar el Despliegue

```powershell
# Verificar que todos los contenedores estÃ¡n corriendo
docker ps

# Ver logs del backend
docker logs financia_backend -f
```

#### 5ï¸âƒ£ Acceder a la AplicaciÃ³n

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Frontend** | http://localhost:3000 | admin@demo.documental.com / Demo2025! |
| **Backend API** | http://localhost:8000/docs | - |
| **MinIO Console** | http://localhost:9001 | admin / [tu_password] |
| **Phoenix UI** | http://localhost:6006 | - |
| **OpenSearch** | http://localhost:9200 | admin / admin |

### InstalaciÃ³n con GPU (AceleraciÃ³n NVIDIA)

Para aprovechar la aceleraciÃ³n GPU en OCR y ML:

```powershell
# 1. Instalar NVIDIA Container Toolkit
# Seguir: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html

# 2. Verificar GPU disponible
nvidia-smi

# 3. Levantar con configuraciÃ³n GPU
docker-compose -f docker-compose.gpu.yml up -d
```

### Primeros Pasos

1. **Login**: Accede a http://localhost:3000 con las credenciales de demo
2. **Subir Documentos**: Ve a "Documentos" â†’ "Subir" y carga tus primeros archivos
3. **BÃºsqueda**: Prueba la bÃºsqueda hÃ­brida en la barra superior
4. **RAG**: Abre el "Asistente IA" y haz preguntas sobre tus documentos
5. **Dashboard**: Explora las mÃ©tricas en el panel de administraciÃ³n

### Scripts de Utilidad

```powershell
# Verificar estado del sistema
.\verify_system.ps1

# Reiniciar servicios
docker-compose restart

# Ver logs de todos los servicios
docker-compose logs -f

# Detener todos los servicios
docker-compose down

# Limpiar volÃºmenes (âš ï¸ borra datos)
docker-compose down -v
```

---

## ğŸ“š DocumentaciÃ³n

### GuÃ­as de Usuario

- **[ğŸ“– Manual de Usuario](docs/USER_GUIDE.md)** - GuÃ­a completa para usuarios finales
- **[ğŸ¬ Script de Demo](docs/DEMO_SCRIPT.md)** - DemostraciÃ³n guiada de funcionalidades
- **[ğŸ§¬ Generador de Datos SintÃ©ticos](docs/SYNTHETIC_DATA_GUIDE.md)** - CÃ³mo generar datos de prueba

### GuÃ­as TÃ©cnicas

- **[ğŸ—ï¸ Arquitectura del Sistema](docs/ARCHITECTURE.md)** - DiseÃ±o tÃ©cnico detallado
- **[ğŸ”§ GuÃ­a de AdministraciÃ³n](docs/ADMIN_GUIDE.md)** - ConfiguraciÃ³n y mantenimiento
- **[ğŸš€ GuÃ­a de Despliegue](docs/DEPLOYMENT_GUIDE.md)** - Despliegue en producciÃ³n
- **[ğŸ“¡ Referencia API](docs/API_REFERENCE.md)** - DocumentaciÃ³n completa de endpoints

### GuÃ­as Especializadas

- **[ğŸ”Œ Conectores](docs/CONNECTORS_GUIDE.md)** - IntegraciÃ³n con SharePoint, SAP DMS, etc.
- **[ğŸ“Š GraphQL](docs/GRAPHQL_QUICKSTART.md)** - API GraphQL y ejemplos
- **[ğŸ” SPARQL](docs/SPARQL_EXAMPLES.md)** - Consultas sobre ontologÃ­a
- **[ğŸ‘ï¸ Observabilidad Phoenix](docs/PHOENIX_OBSERVABILITY.md)** - Monitoreo de LLMs
- **[âš–ï¸ Compliance y Gobernanza](docs/GOVERNANCE.md)** - Cumplimiento normativo

### DocumentaciÃ³n de Desarrollo

- **[ğŸ§ª GuÃ­a de Testing](docs/IMPLEMENTATION_GUIDE.md)** - Testing y QA
- **[ğŸ” AnÃ¡lisis de Riesgo](docs/RFP_ANALYSIS.md)** - AnÃ¡lisis de requisitos
- **[ğŸ“‹ Sistema de ValidaciÃ³n](docs/VALIDATION_SYSTEM.md)** - ValidaciÃ³n de compliance

---

## ğŸ¤ Soporte y Contacto

### Soporte TÃ©cnico

- **Email**: financia2030@tefinancia.es
- **DocumentaciÃ³n**: [docs/](docs/)
- **Issues**: GitHub Issues (repositorio privado)

### Equipo de Desarrollo

**TeFinancia S.A. - FinancIA 2030 Team**

---

## ğŸ“„ Licencia

Â© 2024-2025 **TeFinancia S.A.** - Todos los derechos reservados

Este software es **propietario** y confidencial. El uso, copia, modificaciÃ³n o distribuciÃ³n no autorizada estÃ¡ estrictamente prohibido.

Para consultas sobre licenciamiento: legal@tefinancia.es

---

## ğŸ¯ Roadmap

### âœ… Completado (v1.0)

- âœ… Pipeline completo de procesamiento documental
- âœ… BÃºsqueda hÃ­brida (lÃ©xica + semÃ¡ntica)
- âœ… RAG con citaciÃ³n obligatoria
- âœ… AnÃ¡lisis de riesgo multidimensional
- âœ… Motor de compliance con EU AI Act
- âœ… Observabilidad con Arize Phoenix
- âœ… Conectores SharePoint y SAP DMS
- âœ… API GraphQL
- âœ… Sistema de anotaciones
- âœ… ComparaciÃ³n de documentos

### ğŸš§ En Desarrollo (v1.1)

- ğŸš§ IntegraciÃ³n con Microsoft Teams
- ğŸš§ Workflow de aprobaciones
- ğŸš§ Firma electrÃ³nica
- ğŸš§ Mobile app (iOS/Android)
- ğŸš§ ExportaciÃ³n a blockchain

### âš›ï¸ Planificado (v2.0) - Quantum & GPU Enhancement

**ğŸš€ Plan de Mejora Integral con ComputaciÃ³n CuÃ¡ntica y AceleraciÃ³n GPU**

Ver documento completo: **[QUANTUM_GPU_ENHANCEMENT_PLAN.md](docs/QUANTUM_GPU_ENHANCEMENT_PLAN.md)**

**Objetivos principales:**

- âš¡ **AceleraciÃ³n GPU (NVIDIA RTX)**: Embeddings y FAISS-GPU para reducir tiempo de indexado > 80%
- âš›ï¸ **ComputaciÃ³n CuÃ¡ntica**: OptimizaciÃ³n QUBO para deduplicaciÃ³n y clustering (D-Wave + IBM Qiskit + NVIDIA cuQuantum)
- ğŸ§  **Quantum Machine Learning**: Kernels cuÃ¡nticos para clasificaciÃ³n avanzada
- ğŸ¤– **RAG Optimizado**: LLMs con contexto mejorado y trazabilidad 100%
- ğŸ“Š **Observabilidad Avanzada**: Prometheus + Grafana + Arize Phoenix

**Componentes nuevos (modulares, sin romper app actual):**

1. `gpu-embedding-service` - AceleraciÃ³n de embeddings con GPU
2. `quantum-dedupe-dwave` - DeduplicaciÃ³n con D-Wave Ocean SDK
3. `quantum-dedupe-ibm` - DeduplicaciÃ³n con IBM Qiskit
4. `qml-classifier-nvidia` - ML cuÃ¡ntico con cuQuantum
5. `rag-enhanced-service` - RAG optimizado con GPU

**Beneficios esperados:**

- ğŸš€ IngestiÃ³n 3-5Ã— mÃ¡s rÃ¡pida
- ğŸ¯ +15% precisiÃ³n en deduplicaciÃ³n
- ğŸ“‰ -20-30% reducciÃ³n en revisiÃ³n manual
- âš›ï¸ Capacidades de investigaciÃ³n cuÃ¡ntica sin hardware externo

### ğŸ”® Futuro (v3.0+)

- ğŸ”® Multi-tenancy completo
- ğŸ”® IA explicable (XAI) avanzada
- ğŸ”® FederaciÃ³n de bÃºsqueda
- ğŸ”® IntegraciÃ³n con ERP/CRM
- ğŸ”® AnÃ¡lisis predictivo con quantum computing

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella â­**

Hecho con â¤ï¸ por el equipo de **FinancIA 2030**

</div>
